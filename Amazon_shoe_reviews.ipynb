{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd34d532-f600-4931-b832-be1fc7ac5845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud import bigquery\n",
    "\n",
    "# GCP_PROJECT = \"cedar-heaven-387214\"\n",
    "# BQ_DATASET = \"PLACEHOLDER\"\n",
    "\n",
    "# client = bigquery.Client()\n",
    "\n",
    "# # Create the BigQuery dataset\n",
    "# dataset_id = f\"{GCP_PROJECT}.{BQ_DATASET}\"\n",
    "# dataset = bigquery.Dataset(dataset_id)\n",
    "# dataset.location = \"US\"\n",
    "# try:\n",
    "#     dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "#     print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n",
    "# except exceptions.Conflict:\n",
    "#     print(\"Dataset already exists - choose a new name if the dataset is not under your control\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e377712-342f-42c3-a9cf-5314ed75a4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud import storage\n",
    "\n",
    "# GCP_REGION = \"northamerica-northeast2\"\n",
    "# GCP_BUCKET = \"amazon_shoes_review\"\n",
    "\n",
    "# storage_client = storage.Client()\n",
    "\n",
    "# try:\n",
    "#     bucket = storage_client.bucket(GCP_BUCKET)\n",
    "#     bucket.storage_class = \"STANDARD\"\n",
    "#     new_bucket = storage_client.create_bucket(bucket, location=GCP_REGION)\n",
    "# except exceptions.Conflict:\n",
    "#     print(\"Bucket already exists - choose a new name if the bucket is not under your control\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9adbd36-9d92-4bdf-aed0-3e7cee0c0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import aiplatform\n",
    "\n",
    "# GCP_PROJECT = \"cedar-heaven-387214\"\n",
    "# GCP_REGION = \"northamerica-northeast2\"\n",
    "# EXPERIMENT_NAME = \"example\"\n",
    "\n",
    "# # Vertex AI initialization\n",
    "# aiplatform.init(\n",
    "#     project=GCP_PROJECT,\n",
    "#     location=GCP_REGION,\n",
    "#     experiment=EXPERIMENT_NAME,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822cf48c-5ec1-460b-844f-528c9baf8ceb",
   "metadata": {},
   "source": [
    "Uncomment and run the cell below if needed for google cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2f387a6-e68e-4705-bf18-b60ba7a9c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Amazon-Reviews-Capstone'\n",
      "/home/jupyter/Amazon-Reviews-Capstone\n"
     ]
    }
   ],
   "source": [
    "# %cd Amazon-Reviews-Capstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de6b0079-9776-462a-96e7-1d09058cfc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shoes.tsv\n",
      "CPU times: user 28.5 s, sys: 3.03 s, total: 31.5 s\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loading the data\n",
    "import pandas as pd\n",
    "\n",
    "# Grabbing the bucket where the shoes are if this is first load\n",
    "# bucket_name = 'amazon_shoes_review'\n",
    "# file_path = 'gs://amazon_shoes_review/Shoes.tsv'\n",
    "\n",
    "file_path = 'Shoes.tsv'\n",
    "print(file_path)\n",
    "df = pd.read_csv(file_path, sep='\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd27cc4-3a26-4209-997e-69f593b901c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pickled object\n",
    "with open('shoes.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# Print the loaded object\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08a2b5-72da-4dc4-ab17-65a4afc05a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('shoes.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3cf38f-27d2-4c2b-bfde-2bc6732fe6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from google.cloud import storage\n",
    "\n",
    "# # Create a client instance\n",
    "# storage_client = storage.Client()\n",
    "\n",
    "# # Specify your bucket and CSV file name\n",
    "# bucket = 'amazon_shoes_review'\n",
    "# csv = 'Shoes.tsv'\n",
    "\n",
    "# # Get the bucket and file objects\n",
    "# bucket = storage_client.get_bucket(bucket)\n",
    "# blob = bucket.blob(csv)\n",
    "\n",
    "# # Download the CSV file to a local temporary file\n",
    "# local_file_path = 'Shoes.tsv'\n",
    "# blob.download_to_filename(local_file_path)\n",
    "\n",
    "# # Read the CSV file using pandas or any other library of your choice\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(file_path, sep='\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aead27-d8fd-4195-847a-374d41c42a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c0749-f622-48fe-9973-136fb3de0464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6f680-2d40-4ac0-a125-c735c628e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# pip install -U sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a88a0c-2011-42c0-9157-6a214670db2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f47c8-efd1-4287-842a-87d51954abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_names = df['product_title']\n",
    "product_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e2502d-b573-4d70-9867-e5c1c5890c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = list(product_names)\n",
    "corpus = corpus[0:50000]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3a910-1226-4769-ac3f-9caeac15c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus_embeddings = embedder.encode(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b20ae8-51d4-489a-b13f-dee6b4e099bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ff69c-0dbc-49e5-9437-f9e4ca3b62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_clusters = 2\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c09fb4-a930-4d6f-a394-9459a1eb1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.DataFrame(corpus, columns = ['corpus'])\n",
    "cluster_df['cluster'] = cluster_assignment\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6431f8-7c3b-4beb-86af-6ee167a7c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_shoes = ['running shoe', 'walking shoe', 'flip', 'sandal', 'sneaker'] #flip for flip flop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86728142-6291-45de-a30b-bc74c124dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_shoes = df['product_title'].str.contains('|'.join(common_shoes), case=False, na=False)\n",
    "df_shoes=df[label_shoes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e46f69-3349-4b8a-878d-cece1c0acedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['flip flop']\n",
    "label_test = df['product_title'].str.contains('|'.join(test), case=False, na=False)\n",
    "df_test=df[label_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4764d-cd49-4e32-8127-7f4bba06eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18349a10-5f45-4c17-8269-70edac52a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_others = [' bag ', 'sunglasses', 'wallet', 'ray ban', 'rayban', 'tote', 'handbag', 'purse', 'clutch'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec9154-77f5-4aae-9057-ebefb805a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_others = df['product_title'].str.contains('|'.join(common_others), case=False, na=False)\n",
    "df[label_others]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c97c47-972c-4817-afa0-44eb3f74b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shoes[label_others]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650a615-0c9f-4c5f-a0f7-d32dab641803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe with just product names\n",
    "df_names = df['product_title']\n",
    "df_others = pd.DataFrame(df_names[label_others]) #pd.Dataframe is needed to add the column label after\n",
    "df_shoes = pd.DataFrame(df_names[label_shoes])\n",
    "df_others['label'] = 'others'\n",
    "df_shoes['label'] = 'shoes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee79219-67f4-40d4-b306-990f81628af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining and removing products that have shoes and others tag\n",
    "combined_df = pd.concat([df_others, df_shoes])\n",
    "filtered_df = combined_df[~(label_others & label_shoes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de1d7a-d911-466b-b527-57f0b67e6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_shoes = ['running shoe', 'walking shoe', 'flip', 'sandal', 'sneaker', 'boot', 'crocs', 'skateboarding shoe', 'clog', 'hiking shoe', 'slipper', 'flat', 'pump', 'shoe'] #flip for flip flop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5179cdbc-34ae-4192-b050-3bb0863711be",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_shoes = df['product_title'].str.contains('|'.join(common_shoes), case=False, na=False)\n",
    "df_shoes=df[label_shoes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e07b229-0cd6-4b47-a277-59b45516ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask indicating rows in df1 that are not present in df2\n",
    "mask = ~df.isin(df_shoes)\n",
    "\n",
    "# Filter df1 using the mask to get rows not in df2\n",
    "result = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd48efe3-7e4a-4da4-aa3f-6e8592b550e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result\n",
    "\n",
    "list(result.dropna()['product_title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c380885-3dc8-4b9d-b83f-4533c9719b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shoes['product_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1e734-da5f-497c-a7dc-deecc72afe1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "    \n",
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    print(\"Cluster \", i+1)\n",
    "    print(cluster)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fda04-59f4-4dc0-a033-10a7f8fc0b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed979b1f-a5f5-498b-900b-20d77f10c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f021f3-117f-46cd-b32c-9b99d987751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(pred_df, label):\n",
    "    wc = ' '.join([text for text in pred_df['corpus'][pred_df['cluster'] == label]])\n",
    "    wordcloud = WordCloud(width = 800, height = 500, random_state = 20, max_font_size = 110).generate(wc)\n",
    "    fig7 = plt.figure(figsize=(10,7))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09d696-afd4-4172-b4e2-1cce25cdb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud(cluster_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5820da3-ff2b-4d6d-9a17-3afacb333355",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud(cluster_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23b5f5-f822-41ea-b692-90ceb9476ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_embeddings = embedder.encode(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee29f9-b7ff-464e-9d9a-22beadbfee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus_embeddings = embedder.encode(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e692e78-633b-4ca8-91f3-dc3fd5910062",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_clusters = 2\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a067f9c-68c0-4a2c-a265-dc0b4ec0be57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
