{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25e3fcd-7868-4eb1-8e0b-65d08121122b",
   "metadata": {},
   "source": [
    "# Basic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc884ce-5dad-4c79-a2e4-8d0aebc74b6b",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "## [Notebook Introduction](#note)\n",
    "## [Data Preprocessing](#data)\n",
    "### [Train/Test Split](#train)\n",
    "### [Vectorization](#vector)\n",
    "## [Logistic Regression](#lr)\n",
    "## [Support Vector Machines](#svm)\n",
    "## [XGBoost](#xgb)\n",
    "## [Next Steps](#next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de8cdb-c79a-4ff1-a8e6-836fc5da10ee",
   "metadata": {},
   "source": [
    "<a id=\"note\"></a>\n",
    "## Notebook Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c63a7",
   "metadata": {},
   "source": [
    "The purpose of this notebook is the to try to look more in-depth into different segments of the market. This will include looking at specific shoe types such as running shoes, hiking shoes, boots, clogs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c692937-9190-403a-a5ef-ba8276cbabd3",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813e4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import scipy.sparse as sp\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9f3c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minnetonka Men's Double Deerskin Softsole Mocc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>do not buy  really didn t start to wear them u...</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teva Men's Pajaro Flip-Flop</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>super flip flop</td>\n",
       "      <td>provides great cushion as well as archsupport</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adidas Men's 10K Lifestyle Runner Sneaker</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>badass</td>\n",
       "      <td>getting what u see</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OverBling Sneakers for Men Casual Men Shoes Ge...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>three stars</td>\n",
       "      <td>small</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MESSI 15.3 FG/AG SOCCER SHOES (8.5)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>five stars</td>\n",
       "      <td>my 13 year old son loved these shoes excellent...</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358810</th>\n",
       "      <td>Women's Evette Mid-Shaft Boots</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>what a waste</td>\n",
       "      <td>i purchased this shoe because it looked good  ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358811</th>\n",
       "      <td>Women's Bree Suede Moc Snow Joggers</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>you want it   you need it</td>\n",
       "      <td>this little shoe boot is so great if you re th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358812</th>\n",
       "      <td>Women's CanvasMule Shoes</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cute</td>\n",
       "      <td>the backless mule is very comfortable   cute  ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358813</th>\n",
       "      <td>Birki's Super Birki Unisex Clog</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>graceless and immense   comfy and cool</td>\n",
       "      <td>my garden clogs make my feet look huge  and ev...</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358815</th>\n",
       "      <td>Fox Men's Featherlite Shoe Lace-Up</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>get it all</td>\n",
       "      <td>if you are a fan of  quot extreme sports quot ...</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3846073 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             product_title  star_rating  \\\n",
       "0        Minnetonka Men's Double Deerskin Softsole Mocc...            1   \n",
       "1                              Teva Men's Pajaro Flip-Flop            5   \n",
       "3                adidas Men's 10K Lifestyle Runner Sneaker            5   \n",
       "4        OverBling Sneakers for Men Casual Men Shoes Ge...            3   \n",
       "5                      MESSI 15.3 FG/AG SOCCER SHOES (8.5)            5   \n",
       "...                                                    ...          ...   \n",
       "4358810                     Women's Evette Mid-Shaft Boots            1   \n",
       "4358811                Women's Bree Suede Moc Snow Joggers            5   \n",
       "4358812                           Women's CanvasMule Shoes            5   \n",
       "4358813                    Birki's Super Birki Unisex Clog            5   \n",
       "4358815                 Fox Men's Featherlite Shoe Lace-Up            4   \n",
       "\n",
       "         helpful_votes  total_votes  verified_purchase  \\\n",
       "0                    0            0                  1   \n",
       "1                    0            0                  1   \n",
       "3                    0            6                  1   \n",
       "4                    0            0                  1   \n",
       "5                    1            1                  1   \n",
       "...                ...          ...                ...   \n",
       "4358810              0            0                  0   \n",
       "4358811              1            1                  0   \n",
       "4358812              0            0                  0   \n",
       "4358813             10           11                  0   \n",
       "4358815              1            6                  0   \n",
       "\n",
       "                                review_headline  \\\n",
       "0                                                 \n",
       "1                               super flip flop   \n",
       "3                                        badass   \n",
       "4                                   three stars   \n",
       "5                                    five stars   \n",
       "...                                         ...   \n",
       "4358810                            what a waste   \n",
       "4358811              you want it   you need it    \n",
       "4358812                                    cute   \n",
       "4358813  graceless and immense   comfy and cool   \n",
       "4358815                              get it all   \n",
       "\n",
       "                                               review_body  year  month  \n",
       "0        do not buy  really didn t start to wear them u...  2015      8  \n",
       "1            provides great cushion as well as archsupport  2015      8  \n",
       "3                                       getting what u see  2015      8  \n",
       "4                                                    small  2015      8  \n",
       "5        my 13 year old son loved these shoes excellent...  2015      8  \n",
       "...                                                    ...   ...    ...  \n",
       "4358810  i purchased this shoe because it looked good  ...  2002     10  \n",
       "4358811  this little shoe boot is so great if you re th...  2002     10  \n",
       "4358812  the backless mule is very comfortable   cute  ...  2002      9  \n",
       "4358813  my garden clogs make my feet look huge  and ev...  2002      3  \n",
       "4358815  if you are a fan of  quot extreme sports quot ...  2000      4  \n",
       "\n",
       "[3846073 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edfaa1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minnetonka Men's Double Deerskin Softsole Mocc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>do not buy  really didn t start to wear them u...</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teva Men's Pajaro Flip-Flop</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>super flip flop</td>\n",
       "      <td>provides great cushion as well as archsupport</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adidas Men's 10K Lifestyle Runner Sneaker</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>badass</td>\n",
       "      <td>getting what u see</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OverBling Sneakers for Men Casual Men Shoes Ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>three stars</td>\n",
       "      <td>small</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MESSI 15.3 FG/AG SOCCER SHOES (8.5)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>five stars</td>\n",
       "      <td>my 13 year old son loved these shoes excellent...</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358810</th>\n",
       "      <td>Women's Evette Mid-Shaft Boots</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>what a waste</td>\n",
       "      <td>i purchased this shoe because it looked good  ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358811</th>\n",
       "      <td>Women's Bree Suede Moc Snow Joggers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>you want it   you need it</td>\n",
       "      <td>this little shoe boot is so great if you re th...</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358812</th>\n",
       "      <td>Women's CanvasMule Shoes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cute</td>\n",
       "      <td>the backless mule is very comfortable   cute  ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358813</th>\n",
       "      <td>Birki's Super Birki Unisex Clog</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>graceless and immense   comfy and cool</td>\n",
       "      <td>my garden clogs make my feet look huge  and ev...</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358815</th>\n",
       "      <td>Fox Men's Featherlite Shoe Lace-Up</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>get it all</td>\n",
       "      <td>if you are a fan of  quot extreme sports quot ...</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3846073 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             product_title  star_rating  \\\n",
       "0        Minnetonka Men's Double Deerskin Softsole Mocc...            0   \n",
       "1                              Teva Men's Pajaro Flip-Flop            1   \n",
       "3                adidas Men's 10K Lifestyle Runner Sneaker            1   \n",
       "4        OverBling Sneakers for Men Casual Men Shoes Ge...            0   \n",
       "5                      MESSI 15.3 FG/AG SOCCER SHOES (8.5)            1   \n",
       "...                                                    ...          ...   \n",
       "4358810                     Women's Evette Mid-Shaft Boots            0   \n",
       "4358811                Women's Bree Suede Moc Snow Joggers            1   \n",
       "4358812                           Women's CanvasMule Shoes            1   \n",
       "4358813                    Birki's Super Birki Unisex Clog            1   \n",
       "4358815                 Fox Men's Featherlite Shoe Lace-Up            0   \n",
       "\n",
       "         helpful_votes  total_votes  verified_purchase  \\\n",
       "0                    0            0                  1   \n",
       "1                    0            0                  1   \n",
       "3                    0            6                  1   \n",
       "4                    0            0                  1   \n",
       "5                    1            1                  1   \n",
       "...                ...          ...                ...   \n",
       "4358810              0            0                  0   \n",
       "4358811              1            1                  0   \n",
       "4358812              0            0                  0   \n",
       "4358813             10           11                  0   \n",
       "4358815              1            6                  0   \n",
       "\n",
       "                                review_headline  \\\n",
       "0                                                 \n",
       "1                               super flip flop   \n",
       "3                                        badass   \n",
       "4                                   three stars   \n",
       "5                                    five stars   \n",
       "...                                         ...   \n",
       "4358810                            what a waste   \n",
       "4358811              you want it   you need it    \n",
       "4358812                                    cute   \n",
       "4358813  graceless and immense   comfy and cool   \n",
       "4358815                              get it all   \n",
       "\n",
       "                                               review_body  year  month  \n",
       "0        do not buy  really didn t start to wear them u...  2015      8  \n",
       "1            provides great cushion as well as archsupport  2015      8  \n",
       "3                                       getting what u see  2015      8  \n",
       "4                                                    small  2015      8  \n",
       "5        my 13 year old son loved these shoes excellent...  2015      8  \n",
       "...                                                    ...   ...    ...  \n",
       "4358810  i purchased this shoe because it looked good  ...  2002     10  \n",
       "4358811  this little shoe boot is so great if you re th...  2002     10  \n",
       "4358812  the backless mule is very comfortable   cute  ...  2002      9  \n",
       "4358813  my garden clogs make my feet look huge  and ev...  2002      3  \n",
       "4358815  if you are a fan of  quot extreme sports quot ...  2000      4  \n",
       "\n",
       "[3846073 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('2ClassDf.pkl', 'rb') as f:\n",
    "    df2 = pickle.load(f)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc4162",
   "metadata": {},
   "source": [
    "Dropping any columns that aren't used for NLP instead as there will be a more in-depth analysis for NLP from this point on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c3358b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['helpful_votes', 'total_votes', 'verified_purchase', 'year', 'month'])\n",
    "df2 = df2.drop(columns=['helpful_votes', 'total_votes', 'verified_purchase', 'year', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc0427d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minnetonka Men's Double Deerskin Softsole Mocc...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>do not buy  really didn t start to wear them u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teva Men's Pajaro Flip-Flop</td>\n",
       "      <td>1</td>\n",
       "      <td>super flip flop</td>\n",
       "      <td>provides great cushion as well as archsupport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adidas Men's 10K Lifestyle Runner Sneaker</td>\n",
       "      <td>1</td>\n",
       "      <td>badass</td>\n",
       "      <td>getting what u see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OverBling Sneakers for Men Casual Men Shoes Ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>three stars</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MESSI 15.3 FG/AG SOCCER SHOES (8.5)</td>\n",
       "      <td>1</td>\n",
       "      <td>five stars</td>\n",
       "      <td>my 13 year old son loved these shoes excellent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358810</th>\n",
       "      <td>Women's Evette Mid-Shaft Boots</td>\n",
       "      <td>0</td>\n",
       "      <td>what a waste</td>\n",
       "      <td>i purchased this shoe because it looked good  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358811</th>\n",
       "      <td>Women's Bree Suede Moc Snow Joggers</td>\n",
       "      <td>1</td>\n",
       "      <td>you want it   you need it</td>\n",
       "      <td>this little shoe boot is so great if you re th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358812</th>\n",
       "      <td>Women's CanvasMule Shoes</td>\n",
       "      <td>1</td>\n",
       "      <td>cute</td>\n",
       "      <td>the backless mule is very comfortable   cute  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358813</th>\n",
       "      <td>Birki's Super Birki Unisex Clog</td>\n",
       "      <td>1</td>\n",
       "      <td>graceless and immense   comfy and cool</td>\n",
       "      <td>my garden clogs make my feet look huge  and ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358815</th>\n",
       "      <td>Fox Men's Featherlite Shoe Lace-Up</td>\n",
       "      <td>0</td>\n",
       "      <td>get it all</td>\n",
       "      <td>if you are a fan of  quot extreme sports quot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3846073 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             product_title  star_rating  \\\n",
       "0        Minnetonka Men's Double Deerskin Softsole Mocc...            0   \n",
       "1                              Teva Men's Pajaro Flip-Flop            1   \n",
       "3                adidas Men's 10K Lifestyle Runner Sneaker            1   \n",
       "4        OverBling Sneakers for Men Casual Men Shoes Ge...            0   \n",
       "5                      MESSI 15.3 FG/AG SOCCER SHOES (8.5)            1   \n",
       "...                                                    ...          ...   \n",
       "4358810                     Women's Evette Mid-Shaft Boots            0   \n",
       "4358811                Women's Bree Suede Moc Snow Joggers            1   \n",
       "4358812                           Women's CanvasMule Shoes            1   \n",
       "4358813                    Birki's Super Birki Unisex Clog            1   \n",
       "4358815                 Fox Men's Featherlite Shoe Lace-Up            0   \n",
       "\n",
       "                                review_headline  \\\n",
       "0                                                 \n",
       "1                               super flip flop   \n",
       "3                                        badass   \n",
       "4                                   three stars   \n",
       "5                                    five stars   \n",
       "...                                         ...   \n",
       "4358810                            what a waste   \n",
       "4358811              you want it   you need it    \n",
       "4358812                                    cute   \n",
       "4358813  graceless and immense   comfy and cool   \n",
       "4358815                              get it all   \n",
       "\n",
       "                                               review_body  \n",
       "0        do not buy  really didn t start to wear them u...  \n",
       "1            provides great cushion as well as archsupport  \n",
       "3                                       getting what u see  \n",
       "4                                                    small  \n",
       "5        my 13 year old son loved these shoes excellent...  \n",
       "...                                                    ...  \n",
       "4358810  i purchased this shoe because it looked good  ...  \n",
       "4358811  this little shoe boot is so great if you re th...  \n",
       "4358812  the backless mule is very comfortable   cute  ...  \n",
       "4358813  my garden clogs make my feet look huge  and ev...  \n",
       "4358815  if you are a fan of  quot extreme sports quot ...  \n",
       "\n",
       "[3846073 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b1b03d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ASICS Men's GEL-Contend 3 Running Shoe</td>\n",
       "      <td>5</td>\n",
       "      <td>five stars</td>\n",
       "      <td>this is my second pair but different color  ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>New Balance Women's W850v1 Running Shoe</td>\n",
       "      <td>3</td>\n",
       "      <td>returned for a pair of asics</td>\n",
       "      <td>returned for a pair of asics cumulus  they wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>adidas Performance Women's Galaxy Elite W Runn...</td>\n",
       "      <td>5</td>\n",
       "      <td>five stars</td>\n",
       "      <td>very nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>adidas Performance Men's Thrasher 1.1 M Trail ...</td>\n",
       "      <td>5</td>\n",
       "      <td>five stars</td>\n",
       "      <td>love them  i ordered a 1 2 size larger than no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ASICS Women's GEL-Nimbus 16 Running Shoe</td>\n",
       "      <td>5</td>\n",
       "      <td>five stars</td>\n",
       "      <td>i love these shoes   so comfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357821</th>\n",
       "      <td>M991GL New Balance M991 Men's Running Shoe</td>\n",
       "      <td>5</td>\n",
       "      <td>best running shoes i have found</td>\n",
       "      <td>if you are an avid runner that appreciates com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357844</th>\n",
       "      <td>Nike ACG Air Teocalli XCR : Trail Running Shoes</td>\n",
       "      <td>2</td>\n",
       "      <td>lacks support on rough trails</td>\n",
       "      <td>i ve been running in north face gtx trail shoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357929</th>\n",
       "      <td>Nike ACG Air Teocalli XCR : Trail Running Shoes</td>\n",
       "      <td>5</td>\n",
       "      <td>durable running shoe</td>\n",
       "      <td>being in dire need of some new outdoor running...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358796</th>\n",
       "      <td>M991GL New Balance M991 Men's Running Shoe</td>\n",
       "      <td>5</td>\n",
       "      <td>990 serries</td>\n",
       "      <td>the 990 serries new balance are some of the be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358797</th>\n",
       "      <td>M991GL New Balance M991 Men's Running Shoe</td>\n",
       "      <td>5</td>\n",
       "      <td>these shoes rock</td>\n",
       "      <td>aside from the old school good looks  comfort ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292507 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             product_title  star_rating  \\\n",
       "34                  ASICS Men's GEL-Contend 3 Running Shoe            5   \n",
       "37                 New Balance Women's W850v1 Running Shoe            3   \n",
       "42       adidas Performance Women's Galaxy Elite W Runn...            5   \n",
       "45       adidas Performance Men's Thrasher 1.1 M Trail ...            5   \n",
       "60                ASICS Women's GEL-Nimbus 16 Running Shoe            5   \n",
       "...                                                    ...          ...   \n",
       "4357821         M991GL New Balance M991 Men's Running Shoe            5   \n",
       "4357844    Nike ACG Air Teocalli XCR : Trail Running Shoes            2   \n",
       "4357929    Nike ACG Air Teocalli XCR : Trail Running Shoes            5   \n",
       "4358796         M991GL New Balance M991 Men's Running Shoe            5   \n",
       "4358797         M991GL New Balance M991 Men's Running Shoe            5   \n",
       "\n",
       "                         review_headline  \\\n",
       "34                            five stars   \n",
       "37         returned for a pair of asics    \n",
       "42                            five stars   \n",
       "45                            five stars   \n",
       "60                            five stars   \n",
       "...                                  ...   \n",
       "4357821  best running shoes i have found   \n",
       "4357844    lacks support on rough trails   \n",
       "4357929             durable running shoe   \n",
       "4358796                      990 serries   \n",
       "4358797                 these shoes rock   \n",
       "\n",
       "                                               review_body  \n",
       "34       this is my second pair but different color  ex...  \n",
       "37       returned for a pair of asics cumulus  they wer...  \n",
       "42                                               very nice  \n",
       "45       love them  i ordered a 1 2 size larger than no...  \n",
       "60                    i love these shoes   so comfortable   \n",
       "...                                                    ...  \n",
       "4357821  if you are an avid runner that appreciates com...  \n",
       "4357844  i ve been running in north face gtx trail shoe...  \n",
       "4357929  being in dire need of some new outdoor running...  \n",
       "4358796  the 990 serries new balance are some of the be...  \n",
       "4358797  aside from the old school good looks  comfort ...  \n",
       "\n",
       "[292507 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoe_type1 = [r'running shoe']\n",
    "RSIndex = df['product_title'].str.contains('|'.join(shoe_type1), case=False, na=False)\n",
    "df_rs = df[RSIndex]\n",
    "df_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ac95634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rs = df_rs.sample(50000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a9befc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIcCAYAAADBkf7JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABB3klEQVR4nO3deXxOZ/7/8fdNNkKCIIKI2JeoVlImjJ10LG1pPUoptdXWTVNmqK8qNY3SprqFamsbpaHafltLKtYytN9KrWUwLWJJxFKi2iYk1+8PD/evd5O4iHCHvJ6Px3lMz3Wuc87n3M7MePe6zjkOY4wRAAAAACBPxdxdAAAAAAAUdgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAuIV27typAQMGKDQ0VD4+PipVqpSaNGmiqVOn6syZM+4uT5K0cOFCTZ8+3S3nPnPmjHr16qWKFSvK4XCoW7duefZt06aNHA6Hc/Hx8VGDBg00efJkZWZm3tQ627RpozZt2tzUc1yLCxcu6NVXX1Xjxo3l5+en0qVLq2bNmnrkkUe0YcMGd5cHAHcUD3cXAABFxfvvv68RI0aobt26Gj16tBo0aKCLFy9q69atmjlzprZs2aLPPvvM3WVq4cKF2r17t0aOHHnLz/3yyy/rs88+0+zZs1WzZk2VK1fuqv1r1Kihjz76SJJ08uRJffDBBxo/frySk5M1a9asm1ZnXFzcTTv2tcrKylJUVJR27dql0aNHq2nTppKkAwcO6Msvv9TGjRvVunVrN1cJAHcOhzHGuLsIALjTbdmyRS1btlTHjh31+eefy9vb22V7ZmamEhIS9MADD7ipwv+va9eu2r17tw4dOnTLz92xY0cdO3ZMe/bssfZt06aNTp06pd27dzvbLl26pAYNGujw4cM6d+6cfHx8bma5brVu3Tq1a9dOs2fP1oABA3Jsz87OVrFit2ZiSVZWli5dupTjvgaAOwlT9QDgFnjllVfkcDg0a9asXP9y6eXl5RKasrOzNXXqVNWrV0/e3t6qWLGi+vXrp6NHj7rsV716dfXv3z/H8f48lWz9+vVyOBxatGiRxo0bp8qVK8vPz08dOnTQvn37XPZbvny5Dh8+7DIN7ooZM2aocePGKlWqlEqXLq169erphRdesF7/mTNnNGLECFWpUkVeXl6qUaOGxo0bp4yMDEnSoUOH5HA4tHr1au3du9d53vXr11uP/UceHh66++67lZmZqbNnzzrbjTGKi4vT3XffrRIlSqhs2bLq0aOHfvrpJ2efkSNHytfXV+np6TmO27NnTwUGBurixYvO3+nPU/UyMzM1efJk559ZhQoVNGDAAJ08edLZZ/To0fL391dWVpaz7emnn5bD4dC0adOcbadPn1axYsX09ttv53mtp0+fliQFBQXluv3PoenYsWMaMmSIgoOD5eXlpcqVK6tHjx46ceKEs09ycrIee+wxVaxYUd7e3qpfv75ef/11ZWdnO/tc+bOaOnWqJk+erNDQUHl7e2vdunWSpK1bt+qBBx5QuXLl5OPjo3vuuUeLFy92qeXXX3/VqFGjnFNWy5Urp4iICC1atCjP6wUAtzMAgJvq0qVLpmTJkqZZs2bXvM+QIUOMJPPUU0+ZhIQEM3PmTFOhQgUTHBxsTp486ewXEhJiHn/88Rz7t27d2rRu3dq5vm7dOiPJVK9e3fTp08csX77cLFq0yFSrVs3Url3bXLp0yRhjzA8//GBatGhhKlWqZLZs2eJcjDFm0aJFRpJ5+umnzapVq8zq1avNzJkzzTPPPHPVa/ntt9/MXXfdZXx9fc1rr71mVq1aZcaPH288PDxM586djTHG/P7772bLli3mnnvuMTVq1HCe99y5c3ket3Xr1qZhw4Y52iMiIkyZMmWc12SMMU888YTx9PQ0zz//vElISDALFy409erVM4GBgSY1NdUYY8yOHTuMJPP++++7HO/nn3823t7eJjo6Os/fNysry/ztb38zvr6+ZuLEiSYxMdF88MEHpkqVKqZBgwbm119/NcYYk5CQYCSZzZs3O/etV6+eKVGihOnYsaOzLT4+3kgye/bsyfP6Dx48aDw9PU2dOnXMggULzPHjx/Pse/ToURMUFGTKly9vYmNjzerVq018fLwZOHCg2bt3rzHGmLS0NFOlShVToUIFM3PmTJOQkGCeeuopI8kMHz7c5bySTJUqVUzbtm3NJ598YlatWmUOHjxo1q5da7y8vEzLli1NfHy8SUhIMP379zeSzJw5c5zHGDp0qClZsqSJjY0169atM8uWLTNTpkwxb7/9dp7XAADuRnACgJssNTXVSDK9evW6pv579+41ksyIESNc2r/99lsjybzwwgvOtusNTleCyhWLFy82kpzhyBhjunTpYkJCQnIc86mnnjJlypS5pmv4o5kzZxpJZvHixS7tr776qpFkVq1a5VJ3bmEoN1f6Xrx40Vy8eNGkpKSYF1980UgyM2fOdPbbsmWLkWRef/11l/2PHDliSpQoYf7+978725o0aWKaN2/u0i8uLs5IMrt27XI59x9/3yuhcunSpS77fvfdd0aSiYuLM8YYc+HCBePl5WUmTZpkjLkcaCSZf/zjH6ZEiRLm999/N8ZcDnqVK1e2/gYffvihKVWqlJFkJJmgoCDTr18/8/XXX7v0GzhwoPH09LxqEBszZoyRZL799luX9uHDhxuHw2H27dtnjPn/walmzZomMzPTpW+9evXMPffcYy5evOjS3rVrVxMUFGSysrKMMcaEhYWZbt26Wa8PAAoTpuoBQCFzZcrTn6fgNW3aVPXr19eaNWvyfew/P0N11113SZIOHz5s3bdp06Y6e/asHn30Uf3v//6vTp06dU3nXLt2rXx9fdWjRw+X9ivXdyPX88MPP8jT01Oenp4KCgrSpEmTNHbsWA0dOtTZZ9myZXI4HHrsscd06dIl51KpUiU1btzYZTrggAEDtHnzZpfpi3PmzNG9996rsLCwPOtYtmyZypQpo/vvv9/lHHfffbcqVarkPEfJkiUVGRmp1atXS5ISExNVpkwZjR49WpmZmdq0aZMkafXq1erQoYP1+gcOHKijR49q4cKFeuaZZxQcHKwFCxaodevWLlP/Vq5cqbZt26p+/fp5Hmvt2rVq0KCB8yUTV/Tv31/GGK1du9al/YEHHpCnp6dz/b///a/+85//qE+fPpLk8jt07txZKSkpzt+1adOmWrlypcaMGaP169frt99+s14rALgbwQkAbrLy5curZMmSOnjw4DX1v9qzK5UrV3Zuz4+AgACX9SvPW13LX1z79u2r2bNn6/Dhw3r44YdVsWJFNWvWTImJiVfd7/Tp06pUqZLLs1KSVLFiRXl4eNzQ9dSsWVPfffed/u///k9LlixR48aNFRMTo48//tjZ58SJEzLGKDAw0BmyrizffPONSwDs06ePvL29NXfuXEnSnj179N133+X68oU/OnHihM6ePSsvL68c50hNTXU5R4cOHfTNN9/owoULWr16tdq1a6eAgACFh4dr9erVOnjwoA4ePHhNwUmS/P399eijj+rNN9/Ut99+q507dyowMFDjxo1zPud18uRJVa1a9arHOX36dJ733JXtf/TnvleelRo1alSO32DEiBGS5Pwd3nrrLf3jH//Q559/rrZt26pcuXLq1q2bDhw4cE3XDADuwOvIAeAmK168uNq3b6+VK1fq6NGj1r/AXgk3KSkpOfoeP35c5cuXd677+Pg4X7DwR6dOnXLpV1AGDBigAQMG6MKFC/r66681YcIEde3aVfv371dISEiu+wQEBOjbb7+VMcYlPKWlpenSpUs3VKePj48iIiIkSffee6/atm2rhg0bauTIkeratatKlSql8uXLy+FwaOPGjbm+mOOPbWXLltWDDz6o+fPna/LkyZozZ458fHz06KOPXrWO8uXLKyAgQAkJCbluL126tPOf27dvr/Hjx+vrr7/WmjVrNGHCBGf7qlWrFBoa6lzPj4YNG6pXr16aPn269u/fr6ZNm6pChQo5XizyZwEBAUpJScnRfvz4cec1/tGfg/CV7WPHjtVDDz2U6znq1q0rSfL19dXEiRM1ceJEnThxwjn6dP/99+s///nPtV0oANxijDgBwC0wduxYGWP0xBNP5Ppx1osXL+rLL7+UJLVr106StGDBApc+3333nfbu3evyF+rq1atr586dLv3279/vMtXsenl7e1tHoHx9fdWpUyeNGzdOmZmZ+uGHH/Ls2759e/3yyy/6/PPPXdrnz5/v3F5QAgICNGXKFJ04ccL5RrquXbvKGKNjx44pIiIix9KoUSOXYwwYMEDHjx/XihUrtGDBAnXv3l1lypS56nm7du2q06dPKysrK9dzXAkM0uVpan5+fpo+fbpSU1PVsWNHSZdHorZt26bFixerQYMGzpGevJw+fTrPD/1eCR9XjtGpUyetW7fuqvdF+/bttWfPHn3//fcu7fPnz5fD4VDbtm2vWk/dunVVu3Zt7dixI9ffICIiwiVAXhEYGKj+/fvr0Ucf1b59+/Trr79e9TwA4C6MOAHALRAZGakZM2ZoxIgRCg8P1/Dhw9WwYUNdvHhR27Zt06xZsxQWFqb7779fdevW1ZAhQ/T222+rWLFi6tSpkw4dOqTx48crODhYzz33nPO4ffv21WOPPaYRI0bo4Ycf1uHDhzV16lRVqFAh37U2atRIn376qWbMmKHw8HAVK1ZMEREReuKJJ1SiRAm1aNFCQUFBSk1NVUxMjPz9/XXvvffmebx+/frp3Xff1eOPP65Dhw6pUaNG2rRpk1555RV17tz5mqekXat+/fopNjZWr732mp588km1aNFCQ4YM0YABA7R161a1atVKvr6+SklJ0aZNm9SoUSMNHz7cuX9UVJSqVq2qESNGKDU11TpNT5J69eqljz76SJ07d9azzz6rpk2bytPTU0ePHtW6dev04IMPqnv37pIuj0C2bt1aX375pUJDQ1WzZk1JUosWLeTt7a01a9bomWeesZ5z3bp1evbZZ9WnTx81b95cAQEBSktL06JFi5SQkKB+/fo5RywnTZqklStXqlWrVnrhhRfUqFEjnT17VgkJCYqOjla9evX03HPPaf78+erSpYsmTZqkkJAQLV++XHFxcRo+fLjq1Kljrem9995Tp06ddN9996l///6qUqWKzpw5o7179+r777/XkiVLJEnNmjVT165dddddd6ls2bLau3ev/vWvfykyMlIlS5a0ngcA3MKtr6YAgCJm+/bt5vHHHzfVqlUzXl5extfX19xzzz3mxRdfNGlpac5+WVlZ5tVXXzV16tQxnp6epnz58uaxxx4zR44ccTledna2mTp1qqlRo4bx8fExERERZu3atXm+VW/JkiUu+195Q9ofXxV95swZ06NHD1OmTBnjcDjMlf+rmDdvnmnbtq0JDAw0Xl5epnLlyuaRRx4xO3futF736dOnzbBhw0xQUJDx8PAwISEhZuzYsc63yF2Rn7fq5Wb58uVGkpk4caKzbfbs2aZZs2bG19fXlChRwtSsWdP069fPbN26Ncf+L7zwgpFkgoODnW+C+/O5//j7GmPMxYsXzWuvvWYaN25sfHx8TKlSpUy9evXM0KFDzYEDB1z6vvnmm0aSeeKJJ1zaO3bsaCSZL774wnr9R44cMf/zP//jfH28h4eHKV26tGnWrJl5++23XV7HfqX/wIEDTaVKlYynp6fzz+/EiRPOPocPHza9e/c2AQEBxtPT09StW9dMmzbN5Te4cs9MmzYt17p27NhhHnnkEVOxYkXj6elpKlWqZNq1a+fypsMxY8aYiIgIU7ZsWePt7W1q1KhhnnvuOXPq1CnrdQOAuziMMcZ9sQ0AAAAACj+ecQIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgEWR+wBudna2jh8/rtKlS8vhcLi7HAAAAABuYozR+fPnVblyZRUrdvUxpSIXnI4fP67g4GB3lwEAAACgkDhy5IiqVq161T5FLjiVLl1a0uUfx8/Pz83VAAAAAHCX9PR0BQcHOzPC1RS54HRlep6fnx/BCQAAAMA1PcLDyyEAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALDwcHcBcFV9zHJ3l3BbOjSli7tLAAAAwB2MEScAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwcHtwiouLU2hoqHx8fBQeHq6NGzdetX9GRobGjRunkJAQeXt7q2bNmpo9e/YtqhYAAABAUeThzpPHx8dr5MiRiouLU4sWLfTee++pU6dO2rNnj6pVq5brPo888ohOnDihDz/8ULVq1VJaWpouXbp0iysHAAAAUJQ4jDHGXSdv1qyZmjRpohkzZjjb6tevr27duikmJiZH/4SEBPXq1Us//fSTypUrl69zpqeny9/fX+fOnZOfn1++a79Zqo9Z7u4SbkuHpnRxdwkAAAC4zVxPNnDbVL3MzEwlJSUpKirKpT0qKkqbN2/OdZ8vvvhCERERmjp1qqpUqaI6depo1KhR+u233/I8T0ZGhtLT010WAAAAALgebpuqd+rUKWVlZSkwMNClPTAwUKmpqbnu89NPP2nTpk3y8fHRZ599plOnTmnEiBE6c+ZMns85xcTEaOLEiQVePwAAAICiw+0vh3A4HC7rxpgcbVdkZ2fL4XDoo48+UtOmTdW5c2fFxsZq7ty5eY46jR07VufOnXMuR44cKfBrAAAAAHBnc9uIU/ny5VW8ePEco0tpaWk5RqGuCAoKUpUqVeTv7+9sq1+/vowxOnr0qGrXrp1jH29vb3l7exds8QAAAACKFLeNOHl5eSk8PFyJiYku7YmJiWrevHmu+7Ro0ULHjx/XL7/84mzbv3+/ihUrpqpVq97UegEAAAAUXW6dqhcdHa0PPvhAs2fP1t69e/Xcc88pOTlZw4YNk3R5ml2/fv2c/Xv37q2AgAANGDBAe/bs0ddff63Ro0dr4MCBKlGihLsuAwAAAMAdzq3fcerZs6dOnz6tSZMmKSUlRWFhYVqxYoVCQkIkSSkpKUpOTnb2L1WqlBITE/X0008rIiJCAQEBeuSRRzR58mR3XQIAAACAIsCt33FyB77jdGfiO04AAAC4XrfFd5wAAAAA4HZBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAs3B6c4uLiFBoaKh8fH4WHh2vjxo159l2/fr0cDkeO5T//+c8trBgAAABAUePW4BQfH6+RI0dq3Lhx2rZtm1q2bKlOnTopOTn5qvvt27dPKSkpzqV27dq3qGIAAAAARZFbg1NsbKwGDRqkwYMHq379+po+fbqCg4M1Y8aMq+5XsWJFVapUybkUL178FlUMAAAAoChyW3DKzMxUUlKSoqKiXNqjoqK0efPmq+57zz33KCgoSO3bt9e6deuu2jcjI0Pp6ekuCwAAAABcD7cFp1OnTikrK0uBgYEu7YGBgUpNTc11n6CgIM2aNUtLly7Vp59+qrp166p9+/b6+uuv8zxPTEyM/P39nUtwcHCBXgcAAACAO5+HuwtwOBwu68aYHG1X1K1bV3Xr1nWuR0ZG6siRI3rttdfUqlWrXPcZO3asoqOjnevp6emEJwAAAADXxW0jTuXLl1fx4sVzjC6lpaXlGIW6mr/85S86cOBAntu9vb3l5+fnsgAAAADA9XBbcPLy8lJ4eLgSExNd2hMTE9W8efNrPs62bdsUFBRU0OUBAAAAgJNbp+pFR0erb9++ioiIUGRkpGbNmqXk5GQNGzZM0uVpdseOHdP8+fMlSdOnT1f16tXVsGFDZWZmasGCBVq6dKmWLl3qzssAAAAAcIdza3Dq2bOnTp8+rUmTJiklJUVhYWFasWKFQkJCJEkpKSku33TKzMzUqFGjdOzYMZUoUUINGzbU8uXL1blzZ3ddAgAAAIAiwGGMMe4u4lZKT0+Xv7+/zp07Vyifd6o+Zrm7S7gtHZrSxd0lAAAA4DZzPdnArR/ABQAAAIDbAcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsHB7cIqLi1NoaKh8fHwUHh6ujRs3XtN+//73v+Xh4aG777775hYIAAAAoMhza3CKj4/XyJEjNW7cOG3btk0tW7ZUp06dlJycfNX9zp07p379+ql9+/a3qFIAAAAARZlbg1NsbKwGDRqkwYMHq379+po+fbqCg4M1Y8aMq+43dOhQ9e7dW5GRkbeoUgAAAABFmduCU2ZmppKSkhQVFeXSHhUVpc2bN+e535w5c/Tjjz9qwoQJ13SejIwMpaenuywAAAAAcD3cFpxOnTqlrKwsBQYGurQHBgYqNTU1130OHDigMWPG6KOPPpKHh8c1nScmJkb+/v7OJTg4+IZrBwAAAFC0uP3lEA6Hw2XdGJOjTZKysrLUu3dvTZw4UXXq1Lnm448dO1bnzp1zLkeOHLnhmgEAAAAULdc2bHMTlC9fXsWLF88xupSWlpZjFEqSzp8/r61bt2rbtm166qmnJEnZ2dkyxsjDw0OrVq1Su3btcuzn7e0tb2/vm3MRAAAAAIoEt404eXl5KTw8XImJiS7tiYmJat68eY7+fn5+2rVrl7Zv3+5chg0bprp162r79u1q1qzZrSodAAAAQBGTrxGngwcPKjQ09IZPHh0drb59+yoiIkKRkZGaNWuWkpOTNWzYMEmXp9kdO3ZM8+fPV7FixRQWFuayf8WKFeXj45OjHQAAAAAKUr6CU61atdSqVSsNGjRIPXr0kI+PT75O3rNnT50+fVqTJk1SSkqKwsLCtGLFCoWEhEiSUlJSrN90AgAAAICbzWGMMde70+7duzV79mx99NFHysjIUM+ePTVo0CA1bdr0ZtRYoNLT0+Xv769z587Jz8/P3eXkUH3McneXcFs6NKWLu0sAAADAbeZ6skG+nnEKCwtTbGysjh07pjlz5ig1NVV//etf1bBhQ8XGxurkyZP5KhwAAAAACqMbejmEh4eHunfvrsWLF+vVV1/Vjz/+qFGjRqlq1arq16+fUlJSCqpOAAAAAHCbGwpOW7du1YgRIxQUFKTY2FiNGjVKP/74o9auXatjx47pwQcfLKg6AQAAAMBt8vVyiNjYWM2ZM0f79u1T586dNX/+fHXu3FnFil3OYaGhoXrvvfdUr169Ai0WAAAAANwhX8FpxowZGjhwoAYMGKBKlSrl2qdatWr68MMPb6g4AAAAACgM8hWcDhw4YO3j5eWlxx9/PD+HBwAAAIBCJV/POM2ZM0dLlizJ0b5kyRLNmzfvhosCAAAAgMIkX8FpypQpKl++fI72ihUr6pVXXrnhogAAAACgMMlXcDp8+LBCQ0NztIeEhCg5OfmGiwIAAACAwiRfwalixYrauXNnjvYdO3YoICDghosCAAAAgMIkX8GpV69eeuaZZ7Ru3TplZWUpKytLa9eu1bPPPqtevXoVdI0AAAAA4Fb5eqve5MmTdfjwYbVv314eHpcPkZ2drX79+vGMEwAAAIA7Tr6Ck5eXl+Lj4/Xyyy9rx44dKlGihBo1aqSQkJCCrg8AAAAA3C5fwemKOnXqqE6dOgVVCwAAAAAUSvkKTllZWZo7d67WrFmjtLQ0ZWdnu2xfu3ZtgRQHAAAAAIVBvoLTs88+q7lz56pLly4KCwuTw+Eo6LoAAAAAoNDIV3D6+OOPtXjxYnXu3Lmg6wEAAACAQidfryP38vJSrVq1CroWAAAAACiU8hWcnn/+eb355psyxhR0PQAAAABQ6ORrqt6mTZu0bt06rVy5Ug0bNpSnp6fL9k8//bRAigMAAACAwiBfwalMmTLq3r17QdcCAAAAAIVSvoLTnDlzCroOAAAAACi08vWMkyRdunRJq1ev1nvvvafz589Lko4fP65ffvmlwIoDAAAAgMIgXyNOhw8f1t/+9jclJycrIyNDHTt2VOnSpTV16lT9/vvvmjlzZkHXCQAAAABuk68Rp2effVYRERH6+eefVaJECWd79+7dtWbNmgIrDgAAAAAKg3y/Ve/f//63vLy8XNpDQkJ07NixAikMAAAAAAqLfI04ZWdnKysrK0f70aNHVbp06RsuCgAAAAAKk3wFp44dO2r69OnOdYfDoV9++UUTJkxQ586dC6o2AAAAACgU8jVV74033lDbtm3VoEED/f777+rdu7cOHDig8uXLa9GiRQVdIwAAAAC4Vb6CU+XKlbV9+3YtWrRI33//vbKzszVo0CD16dPH5WURAAAAAHAnyFdwkqQSJUpo4MCBGjhwYEHWAwAAAACFTr6C0/z586+6vV+/fvkqBgAAAAAKo3wFp2effdZl/eLFi/r111/l5eWlkiVLEpwAAAAA3FHy9Va9n3/+2WX55ZdftG/fPv31r3/l5RAAAAAA7jj5Ck65qV27tqZMmZJjNAoAAAAAbncFFpwkqXjx4jp+/HhBHhIAAAAA3C5fzzh98cUXLuvGGKWkpOidd95RixYtCqQwAAAAACgs8hWcunXr5rLucDhUoUIFtWvXTq+//npB1AUAAAAAhUa+glN2dnZB1wEAAAAAhVaBPuMEAAAAAHeifI04RUdHX3Pf2NjY/JwCAAAAAAqNfAWnbdu26fvvv9elS5dUt25dSdL+/ftVvHhxNWnSxNnP4XAUTJUAAAAA4Eb5Ck7333+/SpcurXnz5qls2bKSLn8Ud8CAAWrZsqWef/75Ai0SAAAAANwpX884vf7664qJiXGGJkkqW7asJk+ezFv1AAAAANxx8hWc0tPTdeLEiRztaWlpOn/+/A0XBQAAAACFSb6CU/fu3TVgwAB98sknOnr0qI4ePapPPvlEgwYN0kMPPVTQNQIAAACAW+XrGaeZM2dq1KhReuyxx3Tx4sXLB/Lw0KBBgzRt2rQCLRAAAAAA3C1fwalkyZKKi4vTtGnT9OOPP8oYo1q1asnX17eg6wMAAAAAt7uhD+CmpKQoJSVFderUka+vr4wxBVUXAAAAABQa+QpOp0+fVvv27VWnTh117txZKSkpkqTBgwfzKnIAAAAAd5x8BafnnntOnp6eSk5OVsmSJZ3tPXv2VEJCQoEVBwAAAACFQb6ecVq1apW++uorVa1a1aW9du3aOnz4cIEUBgAAAACFRb5GnC5cuOAy0nTFqVOn5O3tfcNFAQAAAEBhkq/g1KpVK82fP9+57nA4lJ2drWnTpqlt27YFVhwAAAAAFAb5mqo3bdo0tWnTRlu3blVmZqb+/ve/64cfftCZM2f073//u6BrBAAAAAC3yteIU4MGDbRz5041bdpUHTt21IULF/TQQw9p27ZtqlmzZkHXCAAAAABudd3B6eLFi2rbtq3S09M1ceJELVu2TCtWrNDkyZMVFBR03QXExcUpNDRUPj4+Cg8P18aNG/Psu2nTJrVo0UIBAQEqUaKE6tWrpzfeeOO6zwkAAAAA1+O6p+p5enpq9+7dcjgcN3zy+Ph4jRw5UnFxcWrRooXee+89derUSXv27FG1atVy9Pf19dVTTz2lu+66S76+vtq0aZOGDh0qX19fDRky5IbrAQAAAIDcOIwx5np3ev755+Xp6akpU6bc0MmbNWumJk2aaMaMGc62+vXrq1u3boqJibmmYzz00EPy9fXVv/71r2vqn56eLn9/f507d05+fn75qvtmqj5mubtLuC0dmtLF3SUAAADgNnM92SBfL4fIzMzUBx98oMTEREVERMjX19dle2xs7DUdIykpSWPGjHFpj4qK0ubNm6+pjm3btmnz5s2aPHlynn0yMjKUkZHhXE9PT7+mYwMAAADAFdcVnH766SdVr15du3fvVpMmTSRJ+/fvd+lzrVP4Tp06paysLAUGBrq0BwYGKjU19ar7Vq1aVSdPntSlS5f00ksvafDgwXn2jYmJ0cSJE6+pJgAAAADIzXUFp9q1ayslJUXr1q2TJPXs2VNvvfVWjvBzPf4ctIwx1vC1ceNG/fLLL/rmm280ZswY1apVS48++miufceOHavo6Gjnenp6uoKDg/NdLwAAAICi57qC058fh1q5cqUuXLiQrxOXL19exYsXzzG6lJaWZg1ioaGhkqRGjRrpxIkTeumll/IMTt7e3vL29s5XjQAAAAAg5fM7Tlfk470STl5eXgoPD1diYqJLe2Jiopo3b35dNfzxGSYAAAAAKGjXNeLkcDhyTKO7kdeSR0dHq2/fvoqIiFBkZKRmzZql5ORkDRs2TNLlaXbHjh3T/PnzJUnvvvuuqlWrpnr16km6/F2n1157TU8//XS+awAAAAAAm+ueqte/f3/n1Lfff/9dw4YNy/FWvU8//fSajtezZ0+dPn1akyZNUkpKisLCwrRixQqFhIRIklJSUpScnOzsn52drbFjx+rgwYPy8PBQzZo1NWXKFA0dOvR6LgMAAAAArst1fcdpwIAB19Rvzpw5+S7oZuM7TncmvuMEAACA63XTvuNUmAMRAAAAANwsN/RyCAAAAAAoCghOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwcHtwiouLU2hoqHx8fBQeHq6NGzfm2ffTTz9Vx44dVaFCBfn5+SkyMlJfffXVLawWAAAAQFHk1uAUHx+vkSNHaty4cdq2bZtatmypTp06KTk5Odf+X3/9tTp27KgVK1YoKSlJbdu21f33369t27bd4soBAAAAFCUOY4xx18mbNWumJk2aaMaMGc62+vXrq1u3boqJibmmYzRs2FA9e/bUiy++eE3909PT5e/vr3PnzsnPzy9fdd9M1ccsd3cJt6VDU7q4uwQAAADcZq4nG7htxCkzM1NJSUmKiopyaY+KitLmzZuv6RjZ2dk6f/68ypUrl2efjIwMpaenuywAAAAAcD3cFpxOnTqlrKwsBQYGurQHBgYqNTX1mo7x+uuv68KFC3rkkUfy7BMTEyN/f3/nEhwcfEN1AwAAACh63P5yCIfD4bJujMnRlptFixbppZdeUnx8vCpWrJhnv7Fjx+rcuXPO5ciRIzdcMwAAAICixcNdJy5fvryKFy+eY3QpLS0txyjUn8XHx2vQoEFasmSJOnTocNW+3t7e8vb2vuF6AQAAABRdbhtx8vLyUnh4uBITE13aExMT1bx58zz3W7Rokfr376+FCxeqSxdeCAAAAADg5nPbiJMkRUdHq2/fvoqIiFBkZKRmzZql5ORkDRs2TNLlaXbHjh3T/PnzJV0OTf369dObb76pv/zlL87RqhIlSsjf399t1wEAAADgzubW4NSzZ0+dPn1akyZNUkpKisLCwrRixQqFhIRIklJSUly+6fTee+/p0qVLevLJJ/Xkk0862x9//HHNnTv3VpcPAAAAoIhw63ec3IHvON2Z+I4TAAAArtdt8R0nAAAAALhduHWqHgD3YXQzfxjdBACgaGLECQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFm4PTnFxcQoNDZWPj4/Cw8O1cePGPPumpKSod+/eqlu3rooVK6aRI0feukIBAAAAFFluDU7x8fEaOXKkxo0bp23btqlly5bq1KmTkpOTc+2fkZGhChUqaNy4cWrcuPEtrhYAAABAUeXW4BQbG6tBgwZp8ODBql+/vqZPn67g4GDNmDEj1/7Vq1fXm2++qX79+snf3/8WVwsAAACgqHJbcMrMzFRSUpKioqJc2qOiorR58+YCO09GRobS09NdFgAAAAC4Hm4LTqdOnVJWVpYCAwNd2gMDA5Wamlpg54mJiZG/v79zCQ4OLrBjAwAAACga3P5yCIfD4bJujMnRdiPGjh2rc+fOOZcjR44U2LEBAAAAFA0e7jpx+fLlVbx48RyjS2lpaTlGoW6Et7e3vL29C+x4AAAAAIoet404eXl5KTw8XImJiS7tiYmJat68uZuqAgAAAICc3DbiJEnR0dHq27evIiIiFBkZqVmzZik5OVnDhg2TdHma3bFjxzR//nznPtu3b5ck/fLLLzp58qS2b98uLy8vNWjQwB2XAAAAAKAIcGtw6tmzp06fPq1JkyYpJSVFYWFhWrFihUJCQiRd/uDtn7/pdM899zj/OSkpSQsXLlRISIgOHTp0K0sHAAAAUIS4NThJ0ogRIzRixIhct82dOzdHmzHmJlcEAAAAAK7c/lY9AAAAACjsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAsPdxcAALizVR+z3N0l3JYOTeni7hIAAH/AiBMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYe7i4AAACgIFQfs9zdJdyWDk3p4u4SgNsCI04AAAAAYEFwAgAAAAALpuoBAAAA14Fpoflzu08LZcQJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsCA4AQAAAIAFwQkAAAAALAhOAAAAAGBBcAIAAAAAC4ITAAAAAFgQnAAAAADAguAEAAAAABYEJwAAAACwIDgBAAAAgAXBCQAAAAAsCE4AAAAAYEFwAgAAAAALghMAAAAAWBCcAAAAAMDC7cEpLi5OoaGh8vHxUXh4uDZu3HjV/hs2bFB4eLh8fHxUo0YNzZw58xZVCgAAAKCocmtwio+P18iRIzVu3Dht27ZNLVu2VKdOnZScnJxr/4MHD6pz585q2bKltm3bphdeeEHPPPOMli5deosrBwAAAFCUuDU4xcbGatCgQRo8eLDq16+v6dOnKzg4WDNmzMi1/8yZM1WtWjVNnz5d9evX1+DBgzVw4EC99tprt7hyAAAAAEWJh7tOnJmZqaSkJI0ZM8alPSoqSps3b851ny1btigqKsql7b777tOHH36oixcvytPTM8c+GRkZysjIcK6fO3dOkpSenn6jl3BTZGf86u4SbkuF9c+zMONeyx/utevHvZY/3GvXj3stf7jXrh/3Wv4UxnvtSk3GGGtftwWnU6dOKSsrS4GBgS7tgYGBSk1NzXWf1NTUXPtfunRJp06dUlBQUI59YmJiNHHixBztwcHBN1A9Chv/6e6uAEUF9xpuFe413Crca7hVCvO9dv78efn7+1+1j9uC0xUOh8Nl3RiTo83WP7f2K8aOHavo6GjnenZ2ts6cOaOAgICrngeu0tPTFRwcrCNHjsjPz8/d5eAOxr2GW4V7DbcK9xpuFe6162eM0fnz51W5cmVrX7cFp/Lly6t48eI5RpfS0tJyjCpdUalSpVz7e3h4KCAgINd9vL295e3t7dJWpkyZ/BdexPn5+fFfRNwS3Gu4VbjXcKtwr+FW4V67PraRpivc9nIILy8vhYeHKzEx0aU9MTFRzZs3z3WfyMjIHP1XrVqliIiIXJ9vAgAAAICC4Na36kVHR+uDDz7Q7NmztXfvXj333HNKTk7WsGHDJF2eZtevXz9n/2HDhunw4cOKjo7W3r17NXv2bH344YcaNWqUuy4BAAAAQBHg1mecevbsqdOnT2vSpElKSUlRWFiYVqxYoZCQEElSSkqKyzedQkNDtWLFCj333HN69913VblyZb311lt6+OGH3XUJRYa3t7cmTJiQY9ojUNC413CrcK/hVuFew63CvXZzOcy1vHsPAAAAAIowt07VAwAAAIDbAcEJAAAAACwITgAAAABgQXACAAAAAAuCE4BCh3fWAACAwobgBKDQ8fb21t69e91dBgAAgJNbv+OE28PPP/+sefPm6cCBAwoKCtLjjz+u4OBgd5eFO0B0dHSu7VlZWZoyZYoCAgIkSbGxsbeyLNyh9u7dq2+++UaRkZGqV6+e/vOf/+jNN99URkaGHnvsMbVr187dJeIO8dtvvykpKUnlypVTgwYNXLb9/vvvWrx4sfr16+em6lBUHDlyRBMmTNDs2bPdXcodg+84IYfKlStr165dCggI0MGDB9W8eXNJUqNGjbR3716dP39e33zzjerVq+fmSnG7K1asmBo3bqwyZcq4tG/YsEERERHy9fWVw+HQ2rVr3VMg7hgJCQl68MEHVapUKf3666/67LPP1K9fPzVu3FjGGG3YsEFfffUV4Qk3bP/+/YqKilJycrIcDodatmypRYsWKSgoSJJ04sQJVa5cWVlZWW6uFHe6HTt2qEmTJtxrBYjghByKFSum1NRUVaxYUY8++qhSU1O1fPlylSxZUhkZGerRo4d8fHy0ZMkSd5eK21xMTIzef/99ffDBBy5/YfX09NSOHTty/JtaIL+aN2+udu3aafLkyfr44481YsQIDR8+XP/85z8lSePGjdN3332nVatWublS3O66d++uS5cuac6cOTp79qyio6O1e/durV+/XtWqVSM4ocB88cUXV93+008/6fnnn+deK0AEJ+Twx+BUo0aNHH+p/fbbb9WjRw8dOXLEjVXiTvHdd9/pscce0/3336+YmBh5enoSnFDg/P39lZSUpFq1aik7O1ve3t769ttv1aRJE0nS7t271aFDB6Wmprq5UtzuAgMDtXr1ajVq1MjZ9uSTT2rZsmVat26dfH19CU4oEMWKFZPD4bjqC5UcDgf3WgHi5RDIlcPhkCRlZGQoMDDQZVtgYKBOnjzpjrJwB7r33nuVlJSkkydPKiIiQrt27XLef8DNUKxYMfn4+LhMES1durTOnTvnvqJwx/jtt9/k4eH6CPm7776rBx54QK1bt9b+/fvdVBnuNEFBQVq6dKmys7NzXb7//nt3l3jHITghV+3bt1eTJk2Unp6e43/kk5OTVb58eTdVhjtRqVKlNG/ePI0dO1YdO3bk346hwFWvXl3//e9/netbtmxRtWrVnOtHjhxxPoMC3Ih69epp69atOdrffvttPfjgg3rggQfcUBXuROHh4VcNR7bRKFw/3qqHHCZMmOCyXrJkSZf1L7/8Ui1btryVJaGI6NWrl/76178qKSlJISEh7i4Hd5Dhw4e7BPKwsDCX7StXruTFECgQ3bt316JFi9S3b98c29555x1lZ2dr5syZbqgMd5rRo0frwoULeW6vVauW1q1bdwsruvPxjBMAAAAAWDBVDwAAAAAsCE4AAAAAYEFwAgAAAAALghMAoFCrXr26pk+f7u4yAABFHMEJAJAv/fv3l8PhkMPhkIeHh6pVq6bhw4fr559/LtDzfPfddxoyZEiBHvNq0tLSNHToUFWrVk3e3t6qVKmS7rvvPm3ZsuWW1QAAKHx4HTkAIN/+9re/ac6cObp06ZL27NmjgQMH6uzZs1q0aFGBnaNChQoFdqxr8fDDD+vixYuaN2+eatSooRMnTmjNmjU6c+bMTTtnZmamvLy8btrxAQA3jhEnAEC+XRmRqVq1qqKiotSzZ0+tWrXKpc+cOXNUv359+fj4qF69eoqLi3Nui4yM1JgxY1z6nzx5Up6ens7vj/x5qt65c+c0ZMgQVaxYUX5+fmrXrp127Njh3Fa8eHElJSVJkowxKleunO69917n/osWLcrzY7dnz57Vpk2b9Oqrr6pt27YKCQlR06ZNNXbsWHXp0sWl35AhQxQYGCgfHx+FhYVp2bJlzu1Lly5Vw4YN5e3trerVq+v11193OU/16tU1efJk9e/fX/7+/nriiSckSZs3b1arVq1UokQJBQcH65lnnnH5TktcXJxq164tHx8fBQYGqkePHnn8yQAAChrBCQBQIH766SclJCTI09PT2fb+++9r3Lhx+uc//6m9e/fqlVde0fjx4zVv3jxJUp8+fbRo0SKXr9vHx8crMDBQrVu3znEOY4y6dOmi1NRUrVixQklJSWrSpInat2+vM2fOyN/fX3fffbfWr18vSdq5c6fzP9PT0yVJ69evz/XYklSqVCmVKlVKn3/+uTIyMnLtk52drU6dOmnz5s1asGCB9uzZoylTpqh48eKSpKSkJD3yyCPq1auXdu3apZdeeknjx4/X3LlzXY4zbdo0hYWFKSkpSePHj9euXbt033336aGHHtLOnTsVHx+vTZs26amnnpIkbd26Vc8884wmTZqkffv2KSEhQa1atbL9sQAACooBACAfHn/8cVO8eHHj6+trfHx8jCQjycTGxjr7BAcHm4ULF7rs9/LLL5vIyEhjjDFpaWnGw8PDfP31187tkZGRZvTo0c71kJAQ88YbbxhjjFmzZo3x8/Mzv//+u8sxa9asad577z1jjDHR0dGma9euxhhjpk+fbnr06GGaNGlili9fbowxpk6dOmbGjBl5Xtcnn3xiypYta3x8fEzz5s3N2LFjzY4dO5zbv/rqK1OsWDGzb9++XPfv3bu36dixo0vb6NGjTYMGDVyuqVu3bi59+vbta4YMGeLStnHjRlOsWDHz22+/maVLlxo/Pz+Tnp6eZ+0AgJuHEScAQL61bdtW27dv17fffqunn35a9913n55++mlJl6fcHTlyRIMGDXKO5JQqVUqTJ0/Wjz/+KOny80sdO3bURx99JEk6ePCgtmzZoj59+uR6vqSkJP3yyy8KCAhwOebBgwedx2zTpo02btyo7OxsbdiwQW3atFGbNm20YcMGpaamav/+/XmOOEmXn3E6fvy4vvjiC913331av369mjRp4hwx2r59u6pWrao6derkuv/evXvVokULl7YWLVrowIEDysrKcrZFRETkuLa5c+e6XNd9992n7OxsHTx4UB07dlRISIhq1Kihvn376qOPPtKvv/6a53UAAAoWwQkAkG++vr6qVauW7rrrLr311lvKyMjQxIkTJV2e0iZdnq63fft257J792598803zmP06dNHn3zyiS5evKiFCxeqYcOGaty4ca7ny87OVlBQkMvxtm/frn379mn06NGSpFatWun8+fP6/vvvtXHjRrVp00atW7fWhg0btG7dOlWsWFH169e/6nX5+PioY8eOevHFF7V582b1799fEyZMkCSVKFHiqvsaY+RwOHK05fbb/fnahg4d6nJdO3bs0IEDB1SzZk2VLl1a33//vfMZrRdffFGNGzfW2bNnr1oPAKBg8FY9AECBmTBhgjp16qThw4ercuXKqlKlin766ac8R5AkqVu3bho6dKgSEhK0cOFC9e3bN8++TZo0UWpqqjw8PFS9evVc+1x5zumdd96Rw+FQgwYNVLlyZW3btk3Lli276mhTXho0aKDPP/9cknTXXXfp6NGj2r9/f66jTg0aNNCmTZtc2jZv3qw6deo4n4PK69p++OEH1apVK88+Hh4e6tChgzp06KAJEyaoTJkyWrt2rR566KHrviYAwPVhxAkAUGDatGmjhg0b6pVXXpEkvfTSS4qJidGbb76p/fv3a9euXZozZ45iY2Od+/j6+urBBx/U+PHjtXfvXvXu3TvP43fo0EGRkZHq1q2bvvrqKx06dEibN2/W//zP/2jr1q0udSxYsECtW7eWw+FQ2bJl1aBBA8XHx6tNmzZ5Hv/06dNq166dFixYoJ07d+rgwYNasmSJpk6dqgcffFCS1Lp1a7Vq1UoPP/ywEhMTdfDgQa1cuVIJCQmSpOeff15r1qzRyy+/rP3792vevHl65513NGrUqKv+dv/4xz+0ZcsWPfnkk9q+fbsOHDigL774wjn1cdmyZXrrrbe0fft2HT58WPPnz1d2drbq1q179T8UAECBIDgBAApUdHS03n//fR05ckSDBw/WBx98oLlz56pRo0Zq3bq15s6dq9DQUJd9+vTpox07dqhly5aqVq1ansd2OBxasWKFWrVqpYEDB6pOnTrq1auXDh06pMDAQGe/tm3bKisryyUktW7dWllZWVcdcSpVqpSaNWumN954Q61atVJYWJjGjx+vJ554Qu+8846z39KlS3Xvvffq0UcfVYMGDfT3v//d+fxSkyZNtHjxYn388ccKCwvTiy++qEmTJql///5X/d3uuusubdiwQQcOHFDLli11zz33aPz48c5Xp5cpU0affvqp2rVrp/r162vmzJlatGiRGjZseNXjAgAKhsPkNvEaAAAAAODEiBMAAAAAWBCcAAAAAMCC4AQAAAAAFgQnAAAAALAgOAEAAACABcEJAAAAACwITgAAAABgQXACAAAAAAuCEwAAAABYEJwAAAAAwILgBAAAAAAWBCcAAAAAsPh/DsEr20V24nYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity check that sampling didn't affect class distribution\n",
    "figure = plt.figure(figsize=(10,6))\n",
    "df_rs['star_rating'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.xlabel('Review Scores')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Counts of Review Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8169f2",
   "metadata": {},
   "source": [
    "After sampling, the classes distribution are still the same. Thus, the first model can be performed which is logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1695ac4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"train\"></a>\n",
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0132640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library needed to split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# assigning Reviewer_Score as target variable and everything else as X \n",
    "X_sample = df_rs.drop(columns=['star_rating'])\n",
    "y_sample = df_rs['star_rating']\n",
    "\n",
    "# splitting the data \n",
    "X_remainder_sample, X_test_sample, y_remainder_sample, y_test_sample = train_test_split(X_sample, y_sample, test_size=0.2, random_state=1, stratify=y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2c14bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a validation set\n",
    "X_train_sample, X_valid_sample, y_train_sample, y_valid_sample = train_test_split(X_remainder_sample, y_remainder_sample, test_size=0.3, random_state=1, stratify=y_remainder_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a0786",
   "metadata": {},
   "source": [
    "<a id=\"vector\"></a>\n",
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1887005",
   "metadata": {},
   "source": [
    "The `review_body` and `review_headline` need to be vectorized so there is only numeric columns before modeling can be done. For vectorizing, bag of words will be used with stop words and min_df as parameters to look for. Stemming will not be used as running stemming with the full dataset is not feasible for run time (a test run with stemming on a sample set only showed a <1% increase so the trade off between run-time and readability for a small increase in accuracy is not worth it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7aeb9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating variables to be vectorized for review_body\n",
    "X_train_review_sample = X_train_sample['review_body']\n",
    "X_valid_review_sample = X_valid_sample['review_body']\n",
    "X_test_review_sample = X_test_sample['review_body']\n",
    "\n",
    "# X_remainder will be needed for when cv is being done\n",
    "X_remainder_review_sample = X_remainder_sample['review_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c65ab6c7-05b1-4936-abb1-fd091e8d1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "bag_body = CountVectorizer(stop_words=\"english\", min_df=10) # the min_df is used to filter out random words that could pop up as well as remove some unnecessary features\n",
    "\n",
    "# Fitting \n",
    "bag_body.fit(X_train_review_sample)\n",
    "\n",
    "# Transform\n",
    "train_bag_sample = bag_body.transform(X_train_review_sample)\n",
    "valid_bag_sample = bag_body.transform(X_valid_review_sample)\n",
    "test_bag_sample = bag_body.transform(X_test_review_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4020d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This count vectorizer is for X_remainder when cv is not done \n",
    "# Instantiate\n",
    "bag_body2 = CountVectorizer(stop_words=\"english\", min_df=10)\n",
    "\n",
    "# Fit\n",
    "bag_body2.fit(X_remainder_review_sample)\n",
    "\n",
    "# Transform\n",
    "remainder_bag_sample = bag_body2.transform(X_remainder_review_sample)\n",
    "test_bag_sample2 = bag_body2.transform(X_test_review_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2916b4d-a6d6-425c-a7cb-1792f8b8564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same process for review_headline\n",
    "X_train_headline_sample = X_train_sample['review_headline']\n",
    "X_valid_headline_sample = X_valid_sample['review_headline']\n",
    "X_test_headline_sample = X_test_sample['review_headline']\n",
    "\n",
    "# X_remainder will be needed for when cv is being done\n",
    "X_remainder_headline_sample = X_remainder_sample['review_headline']\n",
    "\n",
    "# Instantiate\n",
    "bag_headline = CountVectorizer(stop_words=\"english\", min_df=10)\n",
    "\n",
    "# Fitting \n",
    "bag_headline.fit(X_train_headline_sample)\n",
    "\n",
    "# Transform\n",
    "train_headline_sample = bag_headline.transform(X_train_headline_sample)\n",
    "valid_headline_sample = bag_headline.transform(X_valid_headline_sample)\n",
    "test_headline_sample = bag_headline.transform(X_test_headline_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b26d39c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For X_remainder\n",
    "bag_headline2 = CountVectorizer(stop_words=\"english\", min_df=10)\n",
    "bag_headline2.fit(X_remainder_headline_sample)\n",
    "remainder_headline_sample = bag_headline2.transform(X_remainder_headline_sample)\n",
    "test_headline_sample2 = bag_headline2.transform(X_test_headline_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824dc29f-a671-49ce-8b40-8067c4a5a2df",
   "metadata": {},
   "source": [
    "Now that the 2 columns have been vectorized, the bag of words would need to be combined so it can go back into the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b3dfaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining headline and body\n",
    "train_count = sp.hstack([train_headline_sample, train_bag_sample])\n",
    "valid_count = sp.hstack([valid_headline_sample, valid_bag_sample])\n",
    "test_count = sp.hstack([test_headline_sample, test_bag_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68b1b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining headline and bag counts\n",
    "remainder_count = sp.hstack([remainder_headline_sample, remainder_bag_sample])\n",
    "test_count2 = sp.hstack([test_headline_sample2, test_bag_sample2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d1fdb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<28000x3895 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 512062 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "train_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5610ee-0146-49c6-b2ee-f48a9fee85b3",
   "metadata": {},
   "source": [
    "There are ~3900 words after using `CountVectorizer` on `review_headline` and `review_body`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19651220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the words to be used as column headers for the bag of words above\n",
    "body_words = bag_body.get_feature_names_out()\n",
    "# Appending b_ to words from review_body\n",
    "tagged_body_words = ['b_' + feature for feature in body_words]\n",
    "\n",
    "headline_words = bag_headline.get_feature_names_out()\n",
    "# Appending h_ to words from review_headline\n",
    "tagged_headline_words = ['h_' + feature for feature in headline_words]\n",
    "\n",
    "# Combine the two to be used in the column headers\n",
    "sample_vocab = tagged_headline_words + tagged_body_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a53ca811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the process for X_remainder\n",
    "body_words2 = bag_body2.get_feature_names_out()\n",
    "tagged_body_words2 = ['b_' + feature for feature in body_words2]\n",
    "\n",
    "headline_words2 = bag_headline2.get_feature_names_out()\n",
    "tagged_headline_words2 = ['h_' + feature for feature in headline_words2]\n",
    "\n",
    "sample_vocab2 = tagged_headline_words2 + tagged_body_words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94a2e509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3895"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check (should equal to the same number above for train_count\n",
    "len(sample_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b221231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the matrices of bag of words with the column names  \n",
    "train_df = pd.DataFrame(train_count.toarray(), columns=sample_vocab)\n",
    "valid_df = pd.DataFrame(valid_count.toarray(), columns=sample_vocab)\n",
    "test_df = pd.DataFrame(test_count.toarray(), columns=sample_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76c96259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for X_remainder\n",
    "remainder_df = pd.DataFrame(remainder_count.toarray(), columns=sample_vocab2)\n",
    "test_df2 = pd.DataFrame(test_count2.toarray(), columns=sample_vocab2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d624882-b579-4456-aec1-404509a27734",
   "metadata": {},
   "source": [
    "Now that the review_headline and review_body have been vectorized, the string columns can be dropped and replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88beeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping string columns\n",
    "X_train_sample = X_train_sample.reset_index(drop=True).drop(columns=['product_title', 'review_headline', 'review_body'])\n",
    "X_valid_sample = X_valid_sample.reset_index(drop=True).drop(columns=['product_title', 'review_headline', 'review_body'])\n",
    "X_test_sample = X_test_sample.reset_index(drop=True).drop(columns=['product_title', 'review_headline', 'review_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e663541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for X_remainder\n",
    "X_remainder_sample = X_remainder_sample.reset_index(drop=True).drop(columns=['product_title', 'review_headline', 'review_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2dafc68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the dataframe of bag of words back with the original dataframe\n",
    "combined_train = pd.concat([X_train_sample, train_df], axis=1)\n",
    "combined_valid = pd.concat([X_valid_sample, valid_df], axis=1)\n",
    "combined_test = pd.concat([X_test_sample, test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e9e9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for X_remainder\n",
    "combined_remainder = pd.concat([X_remainder_sample, remainder_df], axis=1)\n",
    "combined_test2 = pd.concat([X_test_sample, test_df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01c3ad93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_10</th>\n",
       "      <th>h_100</th>\n",
       "      <th>h_1000</th>\n",
       "      <th>h_11</th>\n",
       "      <th>h_12</th>\n",
       "      <th>h_13</th>\n",
       "      <th>h_14</th>\n",
       "      <th>h_15</th>\n",
       "      <th>h_16</th>\n",
       "      <th>h_19</th>\n",
       "      <th>...</th>\n",
       "      <th>b_yrs</th>\n",
       "      <th>b_zapatos</th>\n",
       "      <th>b_zappos</th>\n",
       "      <th>b_zero</th>\n",
       "      <th>b_zig</th>\n",
       "      <th>b_zigs</th>\n",
       "      <th>b_zigtech</th>\n",
       "      <th>b_zoom</th>\n",
       "      <th>b_zoot</th>\n",
       "      <th>b_zumba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 3895 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       h_10  h_100  h_1000  h_11  h_12  h_13  h_14  h_15  h_16  h_19  ...  \\\n",
       "0         0      0       0     0     0     0     0     0     0     0  ...   \n",
       "1         0      0       0     0     0     0     0     0     0     0  ...   \n",
       "2         0      0       0     0     0     0     0     0     0     0  ...   \n",
       "3         0      0       0     0     0     0     0     0     0     0  ...   \n",
       "4         0      0       0     0     0     0     0     0     0     0  ...   \n",
       "...     ...    ...     ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "27995     0      0       0     0     0     0     0     0     0     0  ...   \n",
       "27996     0      0       0     0     0     0     0     0     0     0  ...   \n",
       "27997     0      0       0     0     0     0     0     0     0     0  ...   \n",
       "27998     0      0       0     0     0     0     0     0     0     0  ...   \n",
       "27999     0      0       0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "       b_yrs  b_zapatos  b_zappos  b_zero  b_zig  b_zigs  b_zigtech  b_zoom  \\\n",
       "0          0          0         0       0      0       0          0       0   \n",
       "1          0          0         0       0      0       0          0       0   \n",
       "2          0          0         0       0      0       0          0       0   \n",
       "3          0          0         0       0      0       0          0       0   \n",
       "4          0          0         0       0      0       0          0       0   \n",
       "...      ...        ...       ...     ...    ...     ...        ...     ...   \n",
       "27995      0          0         0       0      0       0          0       0   \n",
       "27996      0          0         0       0      0       0          0       0   \n",
       "27997      0          0         0       0      0       0          0       0   \n",
       "27998      0          0         0       0      0       0          0       0   \n",
       "27999      0          0         0       0      0       0          0       0   \n",
       "\n",
       "       b_zoot  b_zumba  \n",
       "0           0        0  \n",
       "1           0        0  \n",
       "2           0        0  \n",
       "3           0        0  \n",
       "4           0        0  \n",
       "...       ...      ...  \n",
       "27995       0        0  \n",
       "27996       0        0  \n",
       "27997       0        0  \n",
       "27998       0        0  \n",
       "27999       0        0  \n",
       "\n",
       "[28000 rows x 3895 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check\n",
    "combined_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f2db9-3c3c-41a1-aae2-6525409352df",
   "metadata": {},
   "source": [
    "The last thing to do before feeding the data into the models is that the data will need to be scaled. The `StandardScalar` will be used for basic modeling and could be changed when hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08a71af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Fit and tranform\n",
    "X_train_scaled = ss.fit_transform(combined_train)\n",
    "X_valid_scaled = ss.transform(combined_valid)\n",
    "X_test_scaled = ss.transform(combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9829a783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For X_remainder\n",
    "ss2 = StandardScaler()\n",
    "X_remainder_scaled = ss.fit_transform(combined_remainder)\n",
    "X_test_scaled2 = ss.transform(combined_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf19bb1",
   "metadata": {},
   "source": [
    "<a id=\"lr\"></a>\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513ccaae-7dd4-477b-a2d1-88fb941b45b1",
   "metadata": {},
   "source": [
    "For the first model, logisitic regression, the C values will be manually tuned to showcase manual hyperparameter optimization. After which for other models, gridsearch will be performed for hyperparameter optimization. For the solver to be used in this LR model will be `lbfgs`, `liblinear`, and `saga`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba55963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mager\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mager\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mager\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mager\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "# the c to be iterated through\n",
    "C_range = np.array([.00000001,.0000001,.000001,.00001,.0001,.001,.1,\n",
    "                1,10,100,1000,10000,100000,1000000,10000000,100000000,1000000000])\n",
    "\n",
    "for c in C_range:\n",
    "    log = LogisticRegression(solver='lbfgs', C=c, random_state=1, max_iter=10000)\n",
    "    log.fit(X_train_scaled, y_train_sample)\n",
    "    scores.append(log.score(X_valid_scaled, y_valid_sample))\n",
    "\n",
    "# Visualize the results of each model ran\n",
    "plt.figure()\n",
    "plt.plot(C_range, scores, label=\"Cross Validation Score\",marker='.')\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel('Regularization Parameter: C')\n",
    "plt.ylabel('Cross Validation Score')\n",
    "plt.grid()\n",
    "plt.show();\n",
    "\n",
    "# Print the best model's C value\n",
    "which_max = np.array(scores).argmax()\n",
    "print(\"The best model has C = \",C_range[which_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a9063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring the best result\n",
    "lr = LogisticRegression(solver='lbfgs', C=0.001, random_state=1, max_iter=10000)\n",
    "lr.fit(X_train_scaled, y_train_sample)\n",
    "lr.score(X_test_scaled, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecdfeb0-75b1-46e1-8c74-859aecc14653",
   "metadata": {},
   "source": [
    "| Model                           | Accuracy |\n",
    "|---------------------------------|----------|\n",
    "| Logistic Regression (lbfgs)     | 79.29%   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044a0ac-33ef-471e-a9ad-e90cb833851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the models\n",
    "with open('lr.pkl', 'wb') as f:\n",
    "    pickle.dump(lr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe68c0ee",
   "metadata": {},
   "source": [
    "Test accuracy with the best C value (0.001) is 79.29%. Confusion matrix and classification report should be looked at next to see other metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34323bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rating predictions\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test_sample, y_pred)\n",
    "print(classification_report(y_test_sample, y_pred))\n",
    "\n",
    "# Visualizing confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(lr, X_test_scaled, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c526f",
   "metadata": {},
   "source": [
    "Looking at the classification report, the class imbalance seems to affecting the predictions as f1-score for class 0 is 71% and f1-score for class 1 is 84% which is a 13% difference. This is due to recall of class 0 is 65% and 35% of actual review is being predicted as 1 whereas the recall for 1 is 89%. A big difference of 24%. This will need to be addressed if other models show the same result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing solver liblinear \n",
    "scores = []\n",
    "# Reducing C_range as it seems to plateau after 1 for lbfgs\n",
    "C_range = np.array([.00000001,.0000001,.000001,.00001,.0001,.001,.1,\n",
    "                1,10,100])\n",
    "\n",
    "for c in C_range:\n",
    "    log = LogisticRegression(solver='liblinear', C=c, random_state=1, max_iter=10000)\n",
    "    log.fit(X_train_scaled, y_train_sample)\n",
    "    scores.append(log.score(X_valid_scaled, y_valid_sample))\n",
    "\n",
    "# Visualize the graph\n",
    "plt.figure()\n",
    "plt.plot(C_range, scores, label=\"Cross Validation Score\",marker='.')\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel('Regularization Parameter: C')\n",
    "plt.ylabel('Cross Validation Score')\n",
    "plt.grid()\n",
    "plt.show();\n",
    "\n",
    "# Print the best model's C value\n",
    "which_max = np.array(scores).argmax()\n",
    "print(\"The best model has C = \",C_range[which_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(solver='liblinear', C=0.0001, random_state=1)\n",
    "lr2.fit(X_train_scaled, y_train_sample)\n",
    "lr2.score(X_test_scaled, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17d7f3",
   "metadata": {},
   "source": [
    "A solver of `liblinear` with the best C value (0.0001) had a test score of 80.08%, an increase of <1% compared to the previous solver. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd8076-2bc7-4eed-bc5e-b7b449aefa20",
   "metadata": {},
   "source": [
    "| Model                           | Accuracy |\n",
    "|---------------------------------|----------|\n",
    "| Logistic Regression (lbfgs)     | 79.29%   |\n",
    "| Logistic Regression (liblinear) | 80.08%   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db67394-b92a-4029-9eff-834f33cfc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the models\n",
    "with open('lr2.pkl', 'wb') as f:\n",
    "    pickle.dump(lr2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716765f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rating predictions\n",
    "y_pred = lr2.predict(X_test_scaled)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test_sample, y_pred)\n",
    "print(classification_report(y_test_sample, y_pred))\n",
    "\n",
    "# Visualizing confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(lr2, X_test_scaled, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15877708",
   "metadata": {},
   "source": [
    "The f1-score is slightly better on this solver than lbfgs from 0.71 to 0.73 for class 0 but there is still a big difference of .11 for the f1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing solver saga \n",
    "scores = []\n",
    "# Reducing C_range as it seems to plateau after 1 for lbfgs\n",
    "C_range = np.array([.00000001,.0000001,.000001,.00001,.0001,.001,.1,\n",
    "                1,10,100])\n",
    "\n",
    "for c in C_range:\n",
    "    log = LogisticRegression(solver='saga', C=c, random_state=1, max_iter=10000)\n",
    "    log.fit(X_train_scaled, y_train_sample)\n",
    "    scores.append(log.score(X_valid_scaled, y_valid_sample))\n",
    "\n",
    "# Visualize the graph\n",
    "plt.figure()\n",
    "plt.plot(C_range, scores, label=\"Cross Validation Score\",marker='.')\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel('Regularization Parameter: C')\n",
    "plt.ylabel('Cross Validation Score')\n",
    "plt.grid()\n",
    "plt.show();\n",
    "\n",
    "# Print the best model's C value\n",
    "which_max = np.array(scores).argmax()\n",
    "print(\"The best model has C = \",C_range[which_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdfe86-0e77-43ee-a514-3c547e47194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3 = LogisticRegression(solver='saga', C=0.001, random_state=1, max_iter=10000)\n",
    "lr3.fit(X_train_scaled, y_train_sample)\n",
    "lr3.score(X_test_scaled, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed17e32-75ec-47f5-859f-ae07b3399bb0",
   "metadata": {},
   "source": [
    "A solver of `saga` with the best C-value (0.001) had a test score accuracy of 79.34% which is ~1% decrease when compared to `liblinear`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f33ea8-24d6-45ea-a8b2-6e0da7e5a68b",
   "metadata": {},
   "source": [
    "| Model                           | Accuracy |\n",
    "|---------------------------------|----------|\n",
    "| Logistic Regression (lbfgs)     | 79.29%   |\n",
    "| Logistic Regression (liblinear) | 80.08%   |\n",
    "| Logistic Regression (saga)      | 79.34%   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd339df-8bc3-45bf-9e18-034d76275670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the models\n",
    "with open('lr3.pkl', 'wb') as f:\n",
    "    pickle.dump(lr3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b4626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get rating predictions\n",
    "y_pred = lr3.predict(X_test_scaled)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test_sample, y_pred)\n",
    "print(classification_report(y_test_sample, y_pred))\n",
    "\n",
    "# Visualizing confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(lr3, X_test_scaled, y_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d210f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.DataFrame({\"counts\":lr2.coef_[0]}, index=combined_train.columns).sort_values(\"counts\", ascending=False)\n",
    "word_counts.head(30).plot(kind=\"bar\", figsize=(15, 5), legend=False)\n",
    "plt.title(\"Top 30 most predictive features of a good review\")\n",
    "plt.ylabel(\"coeff\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7668b2e-3860-4014-9ff7-50c9712459b8",
   "metadata": {},
   "source": [
    "From the graph above, all these words makes sense as a predictor of a good review and the main feature of a shoe that seems to be the best predictor of a good review is comfortability as it is the 7th most predictive feature of a good review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62778f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_counts = pd.DataFrame({\"counts\":lr2.coef_[0]}, index=combined_train.columns).sort_values(\"counts\", ascending=True)\n",
    "word_counts.head(30).plot(kind=\"bar\", figsize=(15, 5), legend=False)\n",
    "plt.title(\"Top 30 most predictive features of a bad review\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c21ea1-16d9-4915-8a72-6d98aa03e058",
   "metadata": {},
   "source": [
    "Again the words seems to make sense on why it could be a predictor of a bad review. For feature extraction of shoes, it seems that shoes that are too small, narrow, tight, and uncomfortable are what makes customers give bad reviews which kind of iterates that what most customer wants in a shoe is comfortability.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2479090-9d66-4283-87f6-ea0422cb3fce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To get the list of words\n",
    "# for word in word_counts.index:\n",
    "#     print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d139e-15fa-4753-9664-7d57ad289246",
   "metadata": {},
   "source": [
    "Next, the type of scaler and penalty will be checked to see if it has an effect on accuracy. This will be used with grid search to streamline the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11148ed3-8c7d-40c3-8e7f-162a7d181ab5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "estimators = [('normalise', StandardScaler()),\n",
    "              ('model', LogisticRegression())]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = {\n",
    "    'normalise': [StandardScaler(), MinMaxScaler(), None],\n",
    "    'model': [LogisticRegression(max_iter=10000)],\n",
    "    'model__solver': ['liblinear'],\n",
    "    'model__penalty': [\"l1\", \"l2\"],\n",
    "    'model__C': [0.0001, 0.001, 0.01] # using the best c values from the earlier modeling\n",
    "}\n",
    "\n",
    "grid_LR = GridSearchCV(pipe, param_grid, cv=5, verbose=2)\n",
    "fittedgrid_LR = grid_LR.fit(combined_remainder, y_remainder_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd169194-0bbd-4012-a527-6eb1f442fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the models\n",
    "with open('gridlr.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_LR, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8c1ce-f3d4-43d0-8b89-3f3aa4eca8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedgrid_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c939a-d409-4b67-a772-1bdac4561348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring the best model\n",
    "lr_grid = LogisticRegression(C=0.01, max_iter=10000, penalty='l1', solver='liblinear')\n",
    "lr_grid.fit(X_remainder_scaled, y_remainder_sample) # Using remainder insted of validation as no hyperparameter optimization needed\n",
    "lr_grid.score(X_test_scaled2, y_test_sample)  # X_test_scaled2 is because the model was fit with X_remainder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3efbe70-281e-42df-8de4-ee6f1fa7a519",
   "metadata": {},
   "source": [
    "| Model                           | Accuracy |\n",
    "|---------------------------------|----------|\n",
    "| Logistic Regression (lbfgs)     | 79.29%   |\n",
    "| Logistic Regression (liblinear) | 80.08%   |\n",
    "| Logistic Regression (saga)      | 79.34%   |\n",
    "| Logistic Regression (Gridsearch)| 80.64%   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30567c5-7cb2-48d0-ba7b-96ffb0b849ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rating predictions\n",
    "y_pred = lr_grid.predict(X_test_scaled2) # X_test_scaled2 is because the model was fit with X_remainder\n",
    "\n",
    "# Generate confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test_sample, y_pred)\n",
    "print(classification_report(y_test_sample, y_pred))\n",
    "\n",
    "# Visualizing confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(lr_grid, X_test_scaled2, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c2c4e-c89f-43e0-91f6-9e58a2d41921",
   "metadata": {},
   "source": [
    "Looking at the parameters, the best hyperparameter for logistic regression is 0.01, penalty of l1, solver as `liblinear` and scaling the data with `StandardScaler`. The model from this grid search performed ~0.5% better than the previous best hyperparameter model with a test score of 80.64%. Looking at the overall performance of logistic regression, the test score accuracy is around 79% with only a 1% difference between the different models and hyperparameters and a thing to note is that the 1% difference could be due to chance (as cv wasn't performed for the manual hyperparameter optimization) Next, SVM will be looked at to see if it can perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90839d7-b3d4-420a-baed-f0972dcf90a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"svm\"></a>\n",
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dd242d-ff01-457a-9c5d-df77061db58c",
   "metadata": {},
   "source": [
    "SVM has a long run-time with this large dataset so hyperparameter optimization couldn't be performed. Only the default SVM and it's parameter will be explored to get a general idea if SVM can improve the accuracy of the model by a lot (>1%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "SVM = svm.SVC()\n",
    "SVM.fit(X_train_scaled, y_train_sample)\n",
    "score = SVM.score(X_test_scaled, y_test_sample)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4329bb8e-ec93-429f-a514-a526ecb978cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the models\n",
    "with open('SVM.pkl', 'wb') as f:\n",
    "    pickle.dump(SVM, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a897709-eba9-4f4b-8dc0-6c46aed50f3d",
   "metadata": {},
   "source": [
    "| Model                            | Accuracy |\n",
    "|----------------------------------|----------|\n",
    "| Logistic Regression (lbfgs)      | 79.29%   |\n",
    "| Logistic Regression (liblinear)  | 80.08%   |\n",
    "| Logistic Regression (saga)       | 79.34%   |\n",
    "| Logistic Regression (Gridsearch) | 80.64%   |\n",
    "| SVM (Default Parameters)         | 78.65%   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026777e-179d-4756-8278-cbb8d738147f",
   "metadata": {},
   "source": [
    "SVM did not perform any better than logisitic regression in terms of test score accuracy. This might have performed better if hyperparameter optimization was performed but the run-time of an hour for just 1 model (no cv either) with default parameters is not worth the trade off as it could just lead to a small increase in accuracy (<2% increase) like logistic regression. It might have performed better for the confusion matrix and f1-score so that will be examined next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b1d59-3b7a-4bf3-b52d-382276555c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rating predictions\n",
    "y_pred = SVM.predict(X_test_scaled)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test_sample, y_pred)\n",
    "print(classification_report(y_test_sample, y_pred))\n",
    "\n",
    "# Visualizing confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(SVM, X_test_scaled, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c1736",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"xgb\"></a>\n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbcef06-c4eb-4e7f-bd04-f293638a8822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline and grid search for XGBoost\n",
    "estimators = [('model', XGBClassifier())]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = {\n",
    "    'model': [XGBClassifier()],\n",
    "    'model__max_depth': [3, 4, 5, 6],\n",
    "    'model__learning_rate': [0.1, 0.01, 0.001],\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "grid_XGB = GridSearchCV(pipe, param_grid, cv=5)\n",
    "fittedgrid_XGB = grid_XGB.fit(X_remainder_scaled, y_remainder_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108fd890-d8e9-4073-8b69-c87ab74962a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedgrid_XGB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db519954-a9b2-443a-ad1a-d66449f07c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the models\n",
    "with open('gridXGB.pkl', 'wb') as f:\n",
    "    pickle.dump(fittedgrid_XGB, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27faa4df-bbed-4c26-acd3-9c3b157723da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring the best model\n",
    "XGB = XGBClassifier(learning_rate=0.1, max_depth=6, n_estimators = 300)\n",
    "XGB.fit(X_remainder_scaled, y_remainder_sample) # Using remainder insted of validation as no hyperparameter optimization needed\n",
    "XGB.score(X_test_scaled2, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe649f-c3db-41f1-a77c-e4afb57173b6",
   "metadata": {},
   "source": [
    "| Model                                | Accuracy |\n",
    "|--------------------------------------|----------|\n",
    "| Logistic Regression (lbfgs)          | 79.29%   |\n",
    "| Logistic Regression (liblinear)      | 80.08%   |\n",
    "| Logistic Regression (saga)           | 79.34%   |\n",
    "| Logistic Regression (Gridsearch)     | 80.64%   |\n",
    "| SVM (Default Parameters)             | 78.65%   |\n",
    "| XGBoost (Gridsearch)                 | 80.10%   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209fca7d",
   "metadata": {},
   "source": [
    "The best hyperparameter for XGBoost is when `learning_rate` is 0.1, `max_depth` is 6, and `n_estimators` is 300 with a test accuracy of 80.10%. Just slightly below the best performing model by 0.5%. The model seems to be improving still since the best hyper parameter were the highest learning_rate, max_depth, and n_estimators trained with so the model might be able to improve if those hyperparameters were set higher. Next, check the confusion matrix to see if maybe this model might be better in those metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace90e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get rating predictions\n",
    "y_pred = XGB.predict(X_test_scaled2)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test_sample, y_pred)\n",
    "print(classification_report(y_test_sample, y_pred))\n",
    "\n",
    "# Visualizing confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(XGB, X_test_scaled2, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de18d381-727f-4931-b9ec-48b9bdbc925f",
   "metadata": {},
   "source": [
    "XGBoost seems to also be affected by the majority class with a 25% difference for recall between class 0 and 1. When comparing this result to the best logistic regression model, it didn't perform any better. Next, another grid search using more extreme hyperparameters will be performed to see if the model hyperparameters needs to be further increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbc4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another gridsearch to further finetune\n",
    "estimators = [('model', XGBClassifier())]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = {\n",
    "    'model': [XGBClassifier()],\n",
    "    'model__max_depth': [5, 6], # The larger the depth, the longer it takes to run\n",
    "    'model__learning_rate': [1, 0.5], \n",
    "    'model__n_estimators': [500, 1000],\n",
    "}\n",
    "\n",
    "grid_XGB2 = GridSearchCV(pipe, param_grid, cv=5)\n",
    "fittedgrid_XGB2 = grid_XGB2.fit(X_remainder_scaled, y_remainder_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce410e-c261-47d0-a653-cd0569dd3d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and score\n",
    "XGB_params2 = fittedgrid_XGB2.best_params_\n",
    "XGB_params2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05e264-973f-4b3b-b50e-d8ad881d62e6",
   "metadata": {},
   "source": [
    "Since the best hyperparameters for this grid search isn't the largest values but smallest values means that the hyperparameter is close to being one of the best so further gridsearch don't need to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb70ede-9cb6-47f4-8d0e-b84a48adfd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring the best model\n",
    "XGB2 = XGBClassifier(learning_rate=0.5, max_depth=5, n_estimators = 500)\n",
    "XGB2.fit(X_remainder_scaled, y_remainder_sample) # Using remainder insted of validation as no hyperparameter optimization needed\n",
    "XGB2.score(X_test_scaled2, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb89c2c-1078-4f4d-8531-0b1867b30086",
   "metadata": {},
   "source": [
    "| Model                                | Accuracy |\n",
    "|--------------------------------------|----------|\n",
    "| Logistic Regression (lbfgs)          | 79.29%   |\n",
    "| Logistic Regression (liblinear)      | 80.08%   |\n",
    "| Logistic Regression (saga)           | 79.34%   |\n",
    "| Logistic Regression (Gridsearch)     | 80.64%   |\n",
    "| SVM (Default Parameters)             | 78.65%   |\n",
    "| XGBoost (Gridsearch)                 | 80.10%   |\n",
    "| XGBoost (Gridsearch pt.2)            | 80.65%   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a4902b-c460-433d-9a50-3608d3acdc6c",
   "metadata": {},
   "source": [
    "The model has a better test score accuracy by 0.55% than the previous XGBoost grid search. It is also 0.01% better than the best logistic regression model. Therefore, this is the best performing model in terms of test score accuracy (Note: 0.01% might not be significant and could be due to chance). Next, check to see if its the best performing in precision and recall as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c049166b-6ce9-4a40-a3d6-0ecb7b1efc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "with open('gridXGB2.pkl', 'wb') as f:\n",
    "    pickle.dump(fittedgrid_XGB2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791eac9-6ab8-40e0-915c-b069fd4bed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rating predictions\n",
    "y_pred = XGB2.predict(X_test_scaled2)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test_sample, y_pred)\n",
    "print(classification_report(y_test_sample, y_pred))\n",
    "\n",
    "# Visualizing confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(XGB2, X_test_scaled2, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb3198-1de9-477b-9635-e0240162d56c",
   "metadata": {},
   "source": [
    "It is indeed the best model in precision and recall as well as it is greater than the previous best model by 0.01 increase in precision of class 1, and 0.02 increase in recall of class 0, where the other 2 metrics are equal between the two models. Therefore, this XGBoost is the best performing model for all measuring metrics but it is still not the best prediction system as the system overpredicts the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3de784",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_review_sample = X_train_sample['review_body']\n",
    "X_valid_review_sample = X_valid_sample['review_body']\n",
    "X_test_review_sample = X_test_sample['review_body']\n",
    "\n",
    "# X_remainder will be needed for when cv is being done\n",
    "X_remainder_review_sample = X_remainder_sample['review_body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f92f6-61fd-4bdd-8cd5-b84dd2a54927",
   "metadata": {},
   "source": [
    "<a id=\"next\"></a>\n",
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e92f0-5724-4e10-a2f3-677248c6779c",
   "metadata": {},
   "source": [
    "A major problem that kept arising while performing these models is the f1 score of class 0 being so low compared to class 1 and that is because of the imbalance dataset. To solve this problem, downsampling to make it a balanced dataset might resolve this issue and then the same modeling can be performed to see if it results in a better outcome. This will be explored in the next notebook. "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
